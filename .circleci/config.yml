version: 2.1

orbs:
  slack: circleci/slack@3.4.2

aliases:
  - &envVarsDeployDev
      ENV_NAME: "dev"
      GOOGLE_PROJECT_ID: "akecld-saas-dev"
      GOOGLE_COMPUTE_ZONE: "europe-west3-a"
      CLUSTER_NAME: "europe-west3-a"
      GOOGLE_COMPUTE_ZONE_NEXT: "europe-west3-b"
      CLUSTER_NAME_NEXT: "europe-west3-b"

  - &envVarsDeployPreprod
      ENV_NAME: "preprod"
      GOOGLE_PROJECT_ID: "akecld-saas-preprod"
      GOOGLE_COMPUTE_ZONE: "europe-west3-a"
      CLUSTER_NAME: "europe-west3-a"
      GOOGLE_COMPUTE_ZONE_NEXT: "europe-west3-b"
      CLUSTER_NAME_NEXT: "europe-west3-b"

  - &slack-fail-post-step
      post-steps:
        - slack/status:
            channel: ci
            webhook: $SLACK_NIGHTLY_STATUS
            fail_only: true

  - &slack-post-step
      post-steps:
        - slack/status:
            channel: ci
            webhook: $SLACK_NIGHTLY_STATUS
            fail_only: false

  - &dockerCloudDeployerCurrent   # cloudDeployer version used in prod (used for lastest release deployement)
      docker:
        - image: eu.gcr.io/akeneo-cloud/cloud-deployer:7.7
          auth:
            username: _json_key  # default username when using a JSON key file to authenticate
            password: $GCLOUD_SERVICE_KEY_DEV  # JSON service account you created, do not encode to base64

  - &dockerCloudDeployerNext      # cloudDeployer version (used for lastest current deployement)
      docker:
        - image: eu.gcr.io/akeneo-cloud/cloud-deployer:7.7
          auth:
            username: _json_key  # default username when using a JSON key file to authenticate
            password: $GCLOUD_SERVICE_KEY_DEV  # JSON service account you created, do not encode to base64

  - &dockerJenkinsCloudDeployer
      docker:
          - image: eu.gcr.io/akeneo-cloud/jenkinsfile-runner:7.7
            auth:
                username: _json_key  # default username when using a JSON key file to authenticate
                password: $GCLOUD_SERVICE_KEY_DEV  # JSON service account you created, do not encode to base64

jobs:
  checkout:
    parameters:
      PRODUCT_TYPE:
        type: string
        default: ""
    docker:
      - image: alpine/git
    resource_class: small
    steps:
      - checkout
      - run:
         name: Install cUrl
         command: apk --no-cache add curl
      - run:
            name: Install yq
            command: |
                wget https://github.com/mikefarah/yq/releases/download/3.3.1/yq_linux_386
                mv yq_linux_386 /usr/local/bin/yq
                echo "e7fa464149a450d068311a244f403757408a745b  /usr/local/bin/yq" > /tmp/checksum
                sha1sum -c /tmp/checksum
                chmod +x /usr/local/bin/yq
      - run:
          name: Remove MySQL port translation for EE (see BH-664)
          command: yq delete --inplace docker-compose.yml services.mysql.ports
      - run:
          name: Remove MySQL port translation for GRTH (see BH-664)
          command: yq delete --inplace grth/docker-compose.yml services.mysql.ports
      - run:
          name: Remove MySQL port translation for TRIA
          command: yq delete --inplace tria/docker-compose.yml services.mysql.ports
      - when:
            condition:
                not:
                    equal: [master, << pipeline.git.branch >>]
            steps:
                - run:
                      name: Update composer.json if same branch exists in CE for EE
                      command: |
                          curl --output /dev/null --silent --head --fail https://github.com/akeneo/pim-community-dev/tree/${CIRCLE_BRANCH} && \
                              sed -i "s#akeneo/pim-community-dev\": \"dev-master#akeneo/pim-community-dev\": \"dev-${CIRCLE_BRANCH}#" composer.json || \
                              echo "No CE branch $CIRCLE_BRANCH found. I don't touch the EE dependencies."
                - run:
                      name: Update composer.json if same branch exists in CE for GRTH
                      command: |
                          curl --output /dev/null --silent --head --fail https://github.com/akeneo/pim-community-dev/tree/${CIRCLE_BRANCH} && \
                              sed -i "s#akeneo/pim-community-dev\": \"dev-master#akeneo/pim-community-dev\": \"dev-${CIRCLE_BRANCH}#" grth/composer.json || \
                              echo "No CE branch $CIRCLE_BRANCH found. I don't touch the Growth Edition file."
                - run:
                      name: Update composer.json if same branch exists in CE for TRIA
                      command: |
                          curl --output /dev/null --silent --head --fail https://github.com/akeneo/pim-community-dev/tree/${CIRCLE_BRANCH} && \
                              sed -i "s#akeneo/pim-community-dev\": \"dev-master#akeneo/pim-community-dev\": \"dev-${CIRCLE_BRANCH}#" tria/composer.json || \
                              echo "No CE branch $CIRCLE_BRANCH found. I don't touch the Tria file."
      - persist_to_workspace:
          root: ~/
          paths:
            - project
      - store_artifacts:
          path: composer.json
          destination: ee-composer.json
      - store_artifacts:
          path: grth/composer.json
          destination: grth-composer.json
      - store_artifacts:
          path: tria/composer.json
          destination: tria-composer.json
      - store_artifacts:
          path: docker-compose.yml
          destination: ee-docker-compose.yml
      - store_artifacts:
          path: grth/docker-compose.yml
          destination: grth-docker-compose.yml
      - store_artifacts:
          path: tria/docker-compose.yml
          destination: tria-docker-compose.yml

  ##################
  # Build          #
  ##################
  build_srnt_dev:
    machine:
      image: ubuntu-2004:202010-01
    resource_class: medium
    steps:
      - attach_workspace:
            at: ~/
      - run:
          name: Copy docker-compose.override.yml.dist
          command: cp .circleci/docker-compose.override.yml.dist docker-compose.override.yml
      - run:
            name: Creating cache key for PHP Docker image
            command: |
                find Dockerfile docker/ -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum > ~/php-docker-image.hash
                date +%F >> ~/php-docker-image.hash
      - restore_cache:
            name: Restore PHP docker image cache
            key: php-docker-image-{{ .Environment.CACHE_VERSION }}-{{ checksum "~/php-docker-image.hash" }}
      - run:
          name: Build the latest Docker images
          command: |
              ls php-pim-image.tar && docker load -i php-pim-image.tar
              ls php-pim-image.tar || make php-image-dev
              ls php-pim-image.tar || docker save -o php-pim-image.tar akeneo/pim-dev/php:8.0
      - save_cache:
            name: Save PHP docker image cache
            key: php-docker-image-{{ .Environment.CACHE_VERSION }}-{{ checksum "~/php-docker-image.hash" }}
            paths:
                - php-pim-image.tar
      - run:
          name: Setup tests results folder and log folder
          command: mkdir -p var/tests/phpspec var/tests/csfixer var/logs var/tests/screenshots ~/.cache/yarn ~/.cache/Cypress ~/.composer
      - run:
            name: Creating cache key for JS and PHP dependencies
            command: |
                cat yarn.lock > ~/front-dependency.hash && date +%F >> ~/front-dependency.hash
                cat composer.json > ~/back-dependency.hash && date +%F >> ~/back-dependency.hash
      - restore_cache:
            name: Restore cache - yarn and Cypress dependency cache
            keys:
                - frontend-dependency-cache-{{ checksum "~/front-dependency.hash" }}
      - restore_cache:
            name: Restore cache - composer dependency cache
            keys:
                - backend-dependency-cache-{{ checksum "~/back-dependency.hash" }}
      - change_pim_onboarder_branch_steps
      - run:
            name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
            command: |
                sudo chown -R 1000:1000 ../project
                sudo chown -R 1000:1000 ~/.composer
                sudo chown -R 1000:1000 ~/.cache/
      - run:
          name: Install back and front dependencies
          command: make dependencies
          environment:
            YARN_REGISTRY: "http://registry.yarnpkg.com"
      - run:
          name: Install assets
          command: make assets
      - run:
          name: Build css
          command: make css
      - run:
          name: Create hash for front packages
          command: |
              find vendor/akeneo/pim-community-dev/front-packages/akeneo-design-system -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum > ~/akeneo-design-system.hash
              find vendor/akeneo/pim-community-dev/front-packages/measurement -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum > ~/measurement.hash
              find vendor/akeneo/pim-community-dev/front-packages/shared -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum > ~/shared.hash
              find components/tailored-export/front/ -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum > ~/tailored-export.hash
              find vendor/akeneo/pim-community-dev/src/Akeneo/Platform/Job/front/process-tracker -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum > ~/process-tracker.hash
              find vendor/akeneo/pim-community-dev/src/Akeneo/Platform/Bundle/CatalogVolumeMonitoringBundle/front -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum > ~/catalog-volume-monitoring.hash
              date +%F | tee -a ~/akeneo-design-system.hash ~/measurement.hash ~/shared.hash ~/tailored-export.hash ~/catalog-volume-monitoring.hash ~/process-tracker.hash
      - run:
          name: Set front package directories owner to circleci
          command: sudo chown -R 1001:1001 vendor/akeneo/pim-community-dev/ front-packages/
      - restore_cache:
            name: Restore front package DSM cache
            key: front-packages-dsm-{{ checksum "~/akeneo-design-system.hash" }}
      - restore_cache:
            name: Restore front package measurement cache
            key: front-packages-measurement-{{ checksum "~/measurement.hash" }}
      - restore_cache:
            name: Restore front package Shared cache
            key: front-packages-shared-{{ checksum "~/shared.hash" }}
      - restore_cache:
            name: Restore front package Tailored Export cache
            key: front-packages-tailored-export-{{ checksum "~/tailored-export.hash" }}
      - restore_cache:
            name: Restore micro frontend Process Tracker cache
            key: micro-frontend-process-tracker-{{ checksum "~/process-tracker.hash" }}
      - restore_cache:
            name: Restore micro-frontend Catalog Volume Monitoring cache
            key: micro-frontend-catalog-volume-monitoring-{{ checksum "~/catalog-volume-monitoring.hash" }}
      - run:
          name: Set front packages directories owner to docker
          command: sudo chown -R 1000:1000 vendor/akeneo/pim-community-dev/ front-packages/
      - run:
          name: Build front-packages
          command: make front-packages
      - run:
          name: Build Javascript
          command: make javascript-dev
      - run:
            name: Change owner on project dir to have the right to cache the data
            command: sudo chmod -R 777 ../project ~/.cache ~/.composer vendor/akeneo/pim-community-dev/front-packages/ front-packages/
      - save_cache:
            name: Save fontend dependency cache
            paths:
                - ~/.cache
            key: frontend-dependency-cache-{{ checksum "~/front-dependency.hash" }}
      - save_cache:
            name: Save backend dependency cache
            paths:
                - ~/.composer
            key: backend-dependency-cache-{{ checksum "~/back-dependency.hash" }}
      - save_cache:
            name: Save front package DSM cache
            key: front-packages-dsm-{{ checksum "~/akeneo-design-system.hash" }}
            paths:
                - vendor/akeneo/pim-community-dev/front-packages/akeneo-design-system/
      - save_cache:
            name: Save front package measurement cache
            key: front-packages-measurement-{{ checksum "~/measurement.hash" }}
            paths:
                - vendor/akeneo/pim-community-dev/front-packages/measurement/
      - save_cache:
            name: Save front package Shared cache
            key: front-packages-shared-{{ checksum "~/shared.hash" }}
            paths:
                - vendor/akeneo/pim-community-dev/front-packages/shared/
      - save_cache:
            name: Save front package Tailored Export cache
            key: front-packages-tailored-export-{{ checksum "~/tailored-export.hash" }}
            paths:
                - front-packages/tailored-export/
      - save_cache:
            name: Save micro frontend Process Tracker cache
            key: micro-frontend-process-tracker-{{ checksum "~/process-tracker.hash" }}
            paths:
                - vendor/akeneo/pim-community-dev/src/Akeneo/Platform/Job/front/process-tracker/
      - save_cache:
            name: Save micro-frontend Catalog Volume Monitoring cache
            key: micro-frontend-catalog-volume-monitoring-{{ checksum "~/catalog-volume-monitoring.hash" }}
            paths:
                - vendor/akeneo/pim-community-dev/src/Akeneo/Platform/Bundle/CatalogVolumeMonitoringBundle/front/
      - persist_to_workspace:
          root: ~/
          paths:
            - project

  build_srnt_prod:
      environment:
        <<: *envVarsDeployDev
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      working_directory: ~/project
      steps:
          - attach_workspace:
                at: ~/
          - add_ssh_keys:
              fingerprints:
                  - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
          - change_pim_onboarder_branch_steps
          - connector_bigcommerce_checkout_steps
          - set_gcloud_config_dev
          - run:
              name: Define value for next steps
              command: |
                TYPE="srnt"
                TYPE_LONG="serenity"
                IMAGE_TAG=${CIRCLE_SHA1}
                IMAGE_TAG_SHORTED=$(echo ${IMAGE_TAG} | cut -c -7)
                IMAGE_TAG_DATE=$(date +%Y%m%d%H%M%S)
                RELEASE_NAME="v$(date +%Y%m%d%H%M%S)"
                PRODUCT_REFERENCE_TYPE="serenity_instance"
                PRODUCT_REFERENCE_CODE="serenity_${ENV_NAME}"

                echo export TYPE=${TYPE} >> $BASH_ENV
                echo export TYPE_LONG=${TYPE_LONG} >> $BASH_ENV
                echo export IMAGE_TAG=${IMAGE_TAG} >> $BASH_ENV
                echo export IMAGE_TAG_SHORTED=${IMAGE_TAG_SHORTED} >> $BASH_ENV
                echo export IMAGE_TAG_DATE=${IMAGE_TAG_DATE} >> $BASH_ENV
                echo export RELEASE_NAME=${RELEASE_NAME} >> $BASH_ENV
                echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
                echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV

                echo "Image tag: ${IMAGE_TAG}"
                echo "Serenity release name: ${RELEASE_NAME}"
          - run:
              name: Build the Serenity Edition prod image
              command: make -C deployments/ php-image-prod
          - run:
              name: Push the Serenity Edition prod image on docker registry
              command: make -C deployments/ push-php-image-prod
          - run:
              name: Push Terraform modules to GCS
              command: |
                BOTO_CONFIG=/dev/null gsutil -m cp -r deployments/ gs://akecld-terraform-modules/serenity-edition-dev/${IMAGE_TAG}/
          - run:
              name: Persist env vars for next jobs
              command: |
                echo export TYPE=${TYPE} > persisted_env_vars
                echo export TYPE_LONG=${TYPE_LONG} >> persisted_env_vars
                echo export IMAGE_TAG=${IMAGE_TAG} >> persisted_env_vars
                echo export IMAGE_TAG_SHORTED=${IMAGE_TAG_SHORTED} >> persisted_env_vars
                echo export IMAGE_TAG_DATE=${IMAGE_TAG_DATE} >> persisted_env_vars
                echo export RELEASE_NAME=${RELEASE_NAME} >> persisted_env_vars
                echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> persisted_env_vars
                echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> persisted_env_vars
          - persist_to_workspace:
              root: ~/
              paths:
                - project/persisted_env_vars

  build_grth:
    environment:
      <<: *envVarsDeployDev
    machine:
      image: ubuntu-2004:202010-01
    resource_class: medium
    working_directory: ~/project
    steps:
    - attach_workspace:
        at: ~/
    - add_ssh_keys:
        fingerprints:
          - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
    - connector_bigcommerce_checkout_steps
    - set_gcloud_config_dev
    - install_yq
    - when:
        condition:
            not:
                equal: [master, << pipeline.git.branch >>]
        steps:
          - run:
              name: Get last good CE build revision on PR
              command: |
                if curl --output /dev/null --silent --head --fail https://github.com/akeneo/pim-community-dev/tree/${CIRCLE_BRANCH}; then
                  CE_BRANCH=${CIRCLE_BRANCH}
                  CE_COMMIT_HASH=HEAD
                else
                  CE_BRANCH=master
                  CE_COMMIT_HASH=HEAD
                fi

                echo export CE_BRANCH=${CE_BRANCH} >> $BASH_ENV
                echo export CE_COMMIT_HASH=${CE_COMMIT_HASH} >> $BASH_ENV
    - when:
        condition:
            equal: [master, << pipeline.git.branch >>]
        steps:
          - run:
              name: Get last good CE build revision on master
              command: |
                docker run --rm -v ${PWD}/last_good_ce:/app composer composer install
                CE_BRANCH=master
                CE_COMMIT_HASH=$(docker run --rm -v ${PWD}/last_good_ce:/app composer php get_last_good_ce_revision.php)

                echo export CE_BRANCH=${CE_BRANCH} >> $BASH_ENV
                echo export CE_COMMIT_HASH=${CE_COMMIT_HASH} >> $BASH_ENV
    - run:
        name: Define value for next steps
        command: |
          TYPE="grth"
          TYPE_LONG="growth"
          IMAGE_TAG=$(echo growth-${CIRCLE_SHA1} | cut -b 1-40)
          IMAGE_TAG_SHORTED=$(echo ${CIRCLE_SHA1} | cut -c -7)
          IMAGE_TAG_DATE=$(date +%Y%m%d%H%M%S)
          RELEASE_NAME="growth-v$(date +%Y%m%d%H%M%S)"
          PRODUCT_REFERENCE_TYPE="growth_edition_instance"
          PRODUCT_REFERENCE_CODE="growth_edition_${ENV_NAME}"

          echo export TYPE=${TYPE} >> $BASH_ENV
          echo export TYPE_LONG=${TYPE_LONG} >> $BASH_ENV
          echo export IMAGE_TAG=${IMAGE_TAG} >> $BASH_ENV
          echo export IMAGE_TAG_SHORTED=${IMAGE_TAG_SHORTED} >> $BASH_ENV
          echo export IMAGE_TAG_DATE=${IMAGE_TAG_DATE} >> $BASH_ENV
          echo export RELEASE_NAME=${RELEASE_NAME} >> $BASH_ENV
          echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
          echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV

          echo "CE Branch used: ${CE_BRANCH}"
          echo "CE Commit hash used: ${CE_COMMIT_HASH}"
          echo "Image tag: ${IMAGE_TAG}"
          echo "Growth Release name: ${RELEASE_NAME}"
    - run:
        name: Set the right CE branch
        command: |
              docker run --rm -v ${PWD}:/app -e CE_COMMIT_HASH=${CE_COMMIT_HASH} -e CE_BRANCH=${CE_BRANCH} -w /srv/pim/${TYPE} composer bash -c 'composer require "akeneo/pim-community-dev:dev-${CE_BRANCH}#${CE_COMMIT_HASH}" --no-update --ignore-platform-reqs'
    - run:
        name: Prepare chart values
        command: make -C deployments/ prepare-chart-default-values
    - run:
        name: Build the Growth Edition prod image
        command: make -C deployments/ php-image-prod
    - run:
        name: Push the Growth Edition prod image on docker registry
        command: make -C deployments/ push-php-image-prod
    - run:
        name: Push Terraform modules to GCS
        command: |
          BOTO_CONFIG=/dev/null gsutil -m cp -r deployments/ gs://akecld-terraform-modules/growth-edition-dev/${IMAGE_TAG}/
    - run:
        name: Persist env vars for next jobs
        command: |
          echo export TYPE=${TYPE} > persisted_env_vars
          echo export TYPE_LONG=${TYPE_LONG} >> persisted_env_vars
          echo export IMAGE_TAG=${IMAGE_TAG} >> persisted_env_vars
          echo export IMAGE_TAG_SHORTED=${IMAGE_TAG_SHORTED} >> persisted_env_vars
          echo export IMAGE_TAG_DATE=${IMAGE_TAG_DATE} >> persisted_env_vars
          echo export RELEASE_NAME=${RELEASE_NAME} >> persisted_env_vars
          echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> persisted_env_vars
          echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> persisted_env_vars
    - persist_to_workspace:
          root: ~/
          paths:
            - project

  build_tria:
    environment:
      <<: *envVarsDeployDev
    machine:
      image: ubuntu-2004:202010-01
    resource_class: medium
    working_directory: ~/project
    steps:
    - attach_workspace:
        at: ~/
    - add_ssh_keys:
        fingerprints:
          - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
    - connector_bigcommerce_checkout_steps
    - set_gcloud_config_dev
    - install_yq
    - when:
        condition:
            not:
                equal: [master, << pipeline.git.branch >>]
        steps:
          - run:
              name: Get last good CE build revision on PR
              command: |
                if curl --output /dev/null --silent --head --fail https://github.com/akeneo/pim-community-dev/tree/${CIRCLE_BRANCH}; then
                  CE_BRANCH=${CIRCLE_BRANCH}
                  CE_COMMIT_HASH=HEAD
                else
                  CE_BRANCH=master
                  CE_COMMIT_HASH=HEAD
                fi

                echo export CE_BRANCH=${CE_BRANCH} >> $BASH_ENV
                echo export CE_COMMIT_HASH=${CE_COMMIT_HASH} >> $BASH_ENV
    - when:
        condition:
            equal: [master, << pipeline.git.branch >>]
        steps:
          - run:
              name: Get last good CE build revision on master
              command: |
                docker run --rm -v ${PWD}/last_good_ce:/app composer composer install
                CE_BRANCH=master
                CE_COMMIT_HASH=$(docker run --rm -v ${PWD}/last_good_ce:/app composer php get_last_good_ce_revision.php)

                echo export CE_BRANCH=${CE_BRANCH} >> $BASH_ENV
                echo export CE_COMMIT_HASH=${CE_COMMIT_HASH} >> $BASH_ENV
    - run:
        name: Define value for next steps
        command: |
          TYPE="tria"
          TYPE_LONG="trial"
          IMAGE_TAG=$(echo trial-${CIRCLE_SHA1} | cut -b 1-40)
          IMAGE_TAG_SHORTED=$(echo ${CIRCLE_SHA1} | cut -c -7)
          IMAGE_TAG_DATE=$(date +%Y%m%d%H%M%S)
          RELEASE_NAME="trial-v$(date +%Y%m%d%H%M%S)"
          PRODUCT_REFERENCE_TYPE="pim_trial_instance"
          PRODUCT_REFERENCE_CODE="pim_trial_${ENV_NAME}"

          echo export TYPE=${TYPE} >> $BASH_ENV
          echo export TYPE_LONG=${TYPE_LONG} >> $BASH_ENV
          echo export IMAGE_TAG=${IMAGE_TAG} >> $BASH_ENV
          echo export IMAGE_TAG_SHORTED=${IMAGE_TAG_SHORTED} >> $BASH_ENV
          echo export IMAGE_TAG_DATE=${IMAGE_TAG_DATE} >> $BASH_ENV
          echo export RELEASE_NAME=${RELEASE_NAME} >> $BASH_ENV
          echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
          echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV

          echo "CE Branch used: ${CE_BRANCH}"
          echo "CE Commit hash used: ${CE_COMMIT_HASH}"
          echo "Image tag: ${IMAGE_TAG}"
          echo "Trial Release name: ${RELEASE_NAME}"
    - run:
        name: Set the right CE branch
        command: |
          docker run --rm -v ${PWD}:/app -e CE_COMMIT_HASH=${CE_COMMIT_HASH} -e CE_BRANCH=${CE_BRANCH} -w /srv/pim/${TYPE} composer bash -c 'composer require "akeneo/pim-community-dev:dev-${CE_BRANCH}#${CE_COMMIT_HASH}" --no-update --ignore-platform-reqs'
    - run:
        name: Prepare chart values
        command: make -C deployments/ prepare-chart-default-values
    - run:
        name: Build the Free Trial Edition prod image
        command: make -C deployments/ php-image-prod
    - run:
        name: Push the Free Trial Edition prod image on docker registry
        command: make -C deployments/ push-php-image-prod
    - run:
        name: Push Terraform modules to GCS
        command: |
          BOTO_CONFIG=/dev/null gsutil -m cp -r deployments/ gs://akecld-terraform-modules/trial-edition-dev/${IMAGE_TAG}/
    - run:
        name: Persist env vars for next jobs
        command: |
          echo export TYPE=${TYPE} > persisted_env_vars
          echo export TYPE_LONG=${TYPE_LONG} >> persisted_env_vars
          echo export IMAGE_TAG=${IMAGE_TAG} >> persisted_env_vars
          echo export IMAGE_TAG_SHORTED=${IMAGE_TAG_SHORTED} >> persisted_env_vars
          echo export IMAGE_TAG_DATE=${IMAGE_TAG_DATE} >> persisted_env_vars
          echo export RELEASE_NAME=${RELEASE_NAME} >> persisted_env_vars
          echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> persisted_env_vars
          echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> persisted_env_vars
    - persist_to_workspace:
          root: ~/
          paths:
            - project

  ##################
  # Tests          #
  ##################
  test_back_static_and_acceptance:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
                command: sudo chown -R 1000:1000 ../project
          - run:
                name: No legacy translation format
                command: PIM_CONTEXT=test make find-legacy-translations
          - run:
                name: Load archived docker image
                command: docker load -i php-pim-image.tar
          - run:
                name: Static tests
                command: PIM_CONTEXT=test make static-back
          - run:
                name: Analyzes source code to flag programming errors, bugs, stylistic errors, and suspicious constructs
                command: PIM_CONTEXT=test make lint-back
          - run:
                name: Code Coupling Detection
                command: PIM_CONTEXT=test make coupling-back
          - run:
                name: Unit tests
                command: PIM_CONTEXT=test make unit-back
          - run:
                name: Acceptance tests
                command: PIM_CONTEXT=test make acceptance-back
          - store_test_results:
                path: var/tests
          - store_artifacts:
                path: var/tests
          - store_artifacts:
                path: var/logs

  test_back_integration_bounded_contexts:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir in order to archive the project into the workspace
                command: sudo chown -R 1000:1000 ../project
          - run:
                name: Start containers
                command: |
                    docker load -i php-pim-image.tar
                    APP_ENV=test C='fpm mysql elasticsearch object-storage pubsub-emulator' make up
                    docker/wait_docker_up.sh
          - run:
                name: Install database
                command: APP_ENV=test make database
          - run:
                name: Data Quality
                command: PIM_CONTEXT=data-quality-insights make data-quality-insights-integration-back
          - run:
                name: Asset Manager
                command: PIM_CONTEXT=asset-manager make asset-manager-integration-back
          - run:
                name: Rules Engine
                command: PIM_CONTEXT=rule-engine make rule-engine-integration-back
          - run:
                name: Tailored Export
                command: PIM_CONTEXT=tailored-export make integration-back
          - run:
              name: Tailored Import
              command: PIM_CONTEXT=tailored-import make integration-back
          - store_test_results:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/logs

  test_back_integration_reference_entities:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir in order to archive the project into the workspace
                command: sudo chown -R 1000:1000 ../project
          - run:
                name: Start containers
                command: |
                    docker load -i php-pim-image.tar
                    APP_ENV=test C='fpm mysql elasticsearch object-storage pubsub-emulator' make up
                    docker/wait_docker_up.sh
          - run:
                name: Install database
                command: APP_ENV=test make database
          - run:
                name: Reference Entities
                command: PIM_CONTEXT=reference-entity make reference-entity-integration-back
          - store_test_results:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/logs

  test_database:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      parallelism: 1
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir in order to archive the project into the workspace
                command: sudo chown -R 1000:1000 ../project
          - run:
                name: Start containers
                command: |
                    docker load -i php-pim-image.tar
                    APP_ENV=test C='fpm mysql elasticsearch object-storage pubsub-emulator' make up
                    docker/wait_docker_up.sh
          - run:
                name: Install database
                command: APP_ENV=dev make database
          - run:
              name: Database test
              command: APP_ENV=dev PIM_CONTEXT=test make test-database-structure

  test_back_phpunit:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      parallelism: 20
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir in order to archive the project into the workspace
                command: sudo chown -R 1000:1000 ../project
          - run:
                name: Start containers
                command: |
                    docker load -i php-pim-image.tar
                    APP_ENV=test C='fpm mysql elasticsearch object-storage pubsub-emulator' make up
                    docker/wait_docker_up.sh
          - run:
                name: Install database
                command: APP_ENV=test make database
          - run:
                name: PhpUnit Integration
                command: PIM_CONTEXT=test make pim-integration-back
          - run:
                name: PhpUnit End to end
                command: PIM_CONTEXT=test make end-to-end-back
          - store_test_results:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/logs

  test_back_behat_legacy:
    machine:
        image: ubuntu-2004:202010-01
    resource_class: medium
    parallelism: 40
    steps:
      - attach_workspace:
          at: ~/
      - run:
          name: Get Behat Suite name to run
          command: |
            TESTSUITE=$(echo $CIRCLE_BRANCH | sed -e 's/^.*-\([^-]*\)$/\1/g')
            if ! [[ $TESTSUITE =~ ^(weasel|chipmunk|raccoon)$ ]] ; then
              TESTSUITE="all"
            fi
            echo "Behat Suite to run: "$TESTSUITE
            echo "export TESTSUITE=$TESTSUITE" >> $BASH_ENV
      - run:
          name: Change owner on project dir in order to archive the project into the workspace
          command: sudo chown -R 1000:1000 ../project
      - run:
          name: Start containers
          command: |
            docker load -i php-pim-image.tar
            APP_ENV=behat C='fpm mysql elasticsearch httpd object-storage selenium pubsub-emulator' make up
            docker/wait_docker_up.sh
      - run:
          name: Install database
          command: APP_ENV=behat make database
      - run:
          name: End to end Behat tests
          command: PIM_CONTEXT=test SUITE=$TESTSUITE make end-to-end-legacy
      - run:
          name: Gather Junit test result files in the same directory to improve the render of failing tests
          command: |
              set -e
              cd var/tests/behat
              sudo chmod -R 777 .
              for subdir in */*; do mv "${subdir}" "${subdir/\//_}"; done
          when: always
      - store_test_results:
          path: var/tests/behat
      - store_artifacts:
          path: var/tests/behat
      - store_artifacts:
          path: var/logs
      - store_artifacts:
          path: var/tests/screenshots

  test_front_code_style:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
        - attach_workspace:
            at: ~/
        - run:
              name: Create yarn cache folder
              command: mkdir -p  ~/.cache/yarn
        - run:
              name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
              command: sudo chown -R 1000:1000 ../project ~/.cache/yarn
        - run:
            name: Front type checking
            command: make javascript-dev-strict
        - run:
            name: Front linter
            command: PIM_CONTEXT=test make lint-front

  test_front_static_acceptance_and_integration:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
        - attach_workspace:
            at: ~/
        - run:
              name: Create yarn cache folder
              command: mkdir -p  ~/.cache/yarn
        - run:
              name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
              command: sudo chown -R 1000:1000 ../project ~/.cache/yarn
        - run:
            name: Front unit tests
            command: PIM_CONTEXT=test make unit-front

  test_front_end_to_end:
      machine:
          image: ubuntu-1604:201903-01
      resource_class: large
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir in order to archive the project into the workspace
                command: sudo chown -R 1000:1000 ../project
          - run:
                name: Create yarn cache folder
                command: mkdir -p  ~/.cache/yarn
          - run:
                name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
                command: sudo chown -R 1000:1000 ../project ~/.cache/yarn
          - run:
                name: Start containers
                command: |
                    docker load -i php-pim-image.tar
                    APP_ENV=behat C='fpm mysql elasticsearch httpd object-storage pubsub-emulator' make up
                    docker/wait_docker_up.sh
          - run:
                name: Install database
                command: APP_ENV=behat O="--catalog src/Akeneo/Platform/Bundle/InstallerBundle/Resources/fixtures/icecat_demo_dev" make database
          - run:
                name: Create adminakeneo user
                command: |
                    APP_ENV=behat docker-compose run --rm -u www-data:www-data php bin/console pim:user:create adminakeneo Q7sKB5xP2ttc5KnqFPOF1BrOkTRSulmEj528BpJzbDcLbYSHU1 product-team@akeneo.com admin1 admin2 en_US --admin -n
          - run:
                name: Launch Cypress
                command: PIM_CONTEXT=test CYPRESS_defaultCommandTimeout=8000 CYPRESS_requestTimeout=10000 make end-to-end-front
          - store_artifacts:
                path: cypress/screenshots
          - store_artifacts:
                path: cypress/videos
          - store_artifacts:
                path: var/logs

  test_back_performance:
    machine:
        image: ubuntu-2004:202010-01
    resource_class: medium
    steps:
      - attach_workspace:
          at: ~/
      - run:
          name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
          command: sudo chown -R 1000:1000 ../project
      - run:
          name: Start containers
          command: |
            export ES_JAVA_OPTS='-Xms2g -Xmx2g'
            docker load -i php-pim-image.tar
            APP_ENV=test APP_DEBUG=false C='fpm mysql httpd elasticsearch object-storage blackfire pubsub-emulator' make up
            docker/wait_docker_up.sh
      - run:
          name: Run performance tests
          command: APP_ENV=test .circleci/run_performance_tests.sh
      - store_test_results:
          path: var/tests/phpunit
      - store_artifacts:
          path: var/tests/phpunit
      - store_artifacts:
          path: var/logs

  test_back_missing_structure_migrations:
      machine:
        image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
        -   attach_workspace:
                at: ~/
        -   run:
                name: Load php image
                command: |
                    docker load -i php-pim-image.tar
                    APP_ENV=test C='mysql elasticsearch object-storage pubsub-emulator' make up
                    docker/wait_docker_up.sh
        -   run:
                name: Reset git changes
                command: git checkout -- .
        -   run:
                name: Change owner on project dir after restoring cache
                command: sudo chown -R 1000:1000 ../project
        - run:
                name: Check PIM requirements
                command: |
                    C='mysql elasticsearch' make up
                    docker/wait_docker_up.sh
                    make check-requirements
        -   run:
                name: Test missing database and index structure migrations
                command: vendor/akeneo/pim-community-dev/.circleci/detect_structure_changes.sh $CIRCLE_BRANCH

  test_back_data_migrations:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir in order to archive the project into the workspace
                command: sudo chown -R 1000:1000 ../project
          - run:
                name: Start containers
                command: |
                    docker load -i php-pim-image.tar
                    APP_ENV=test C='fpm mysql elasticsearch object-storage pubsub-emulator' make up
                    docker/wait_docker_up.sh
          - run:
                name: Install database
                command: APP_ENV=test make database
          - run:
                name: PhpUnit Migration
                command: PIM_CONTEXT=test make migration-back
          - store_test_results:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/tests/phpunit
          - store_artifacts:
                path: var/logs

  test_onboarder_bundle:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      environment:
          FLAG_ONBOARDER_ENABLED: 1
      steps:
          - attach_workspace:
                at: ~/
          - run:
                name: Change owner on project dir in order to archive the project into the workspace
                command: |
                  mkdir -p ~/.cache/yarn ~/.composer
                  sudo chown -R 1000:1000 ../project
                  sudo chown -R 1000:1000 ~/.composer
                  sudo chown -R 1000:1000 ~/.cache/yarn
          - run:
                name: Create an empty service account
                command: |
                    mkdir secret
                    echo "{}" > secret/serviceAccount.json
          - run:
                name: Load php pim image
                command: |
                    docker load -i php-pim-image.tar
          - run:
                name: Load make commands
                command: |
                    cp vendor/akeneo/pim-onboarder/onboarder.mk make-file/onboarder.mk
          - run:
                name: Require onboarder tests dependencies
                command: PIM_CONTEXT=onboarder make add-bundle-specific-dev-dependencies
          - run:
                name: Composer update for tests dependencies
                command: docker-compose run -u www-data --rm php php -d memory_limit=4G /usr/local/bin/composer update --no-interaction
          - run:
                name: Add configuration files to run the bundle tests from the PIM
                command: |
                    rm -f docker-compose.override.yml
                    PIM_VERSION=master SETUP_FOR_CI=1 PIM_CONTEXT=onboarder make setup-onboarder-parameters
                    PIM_VERSION=master PIM_CONTEXT=onboarder make setup-onboarder-tests
          - run:
                name: Change owner of PIM as some files have been created with wrong owner
                command: sudo chown -R 1000:1000 ~/project
          - run:
                name: Execute specifications
                command: PIM_CONTEXT=onboarder make test-spec
          - run:
                name: Start containers
                command: |
                  APP_ENV=test C='mysql elasticsearch object-storage pubsub-emulator' make up
                  docker/wait_docker_up.sh
          - run:
                name: Install Akeneo PIM with Onboarder specific configuration (channel, attribute, ...)
                command: PIM_CONTEXT=onboarder ENVIRONMENT=test SETUP_FOR_CI=1 make onboarder-install
          - run:
                name: Execute acceptance tests
                command: PIM_CONTEXT=onboarder make test-acceptance
          - run:
                name: Execute PHPUnit integration tests
                command: PIM_CONTEXT=onboarder make test-integration
          - run:
                name: Start Apache/FPM and Selenium for End to End tests
                command: make up APP_ENV=behat C='fpm httpd selenium'
          - run:
                name: Execute end-to-end tests
                command: PIM_CONTEXT=onboarder make test-end-to-end
          - run:
                name: Execute synchronization end-to-end tests
                command: PIM_CONTEXT=onboarder GITHUB_TOKEN=${GITHUB_TOKEN} make test-synchronization-end-to-end
          - run:
              name: Restart FPM with Onboarder feature turned off
              command: make up APP_ENV=behat FLAG_ONBOARDER_ENABLED=0 C='fpm'
          - run:
              name: Execute end-to-end "Onboarder feature disabled" tests
              command: PIM_CONTEXT=onboarder make test-end-to-end-onboarder-disabled
          - store_test_results:
                path: ~/project/pim/var/tests
          - store_artifacts:
                path: ~/project/pim/var/tests
          - store_artifacts:
                path: ~/project/pim/var/logs

  test_grth:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
              at: ~/
          - run:
              name: Define value for next steps
              command: |
                TYPE="grth"
                echo export TYPE=${TYPE} >> $BASH_ENV
          - run:
              name: Setup tests results folder and log folder
              command: mkdir -p ${TYPE}/var/tests/phpspec ${TYPE}/var/tests/csfixer ${TYPE}/var/logs ${TYPE}/var/tests/screenshots ~/.cache/yarn ~/.composer ~/.cache/Cypress
          - run:
              name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
              command: sudo chown -R 1000:1000 ~/project ~/.cache ~/.composer
          - run:
              name: Load php image
              command: docker load -i php-pim-image.tar
          - run:
              name: Install dependencies
              command: make dependencies
          - run:
              name: Launch Grth in test mode
              command: make pim-test
          - run:
              name: Lint Back
              command: PIM_CONTEXT=test make lint-back
          - run:
              name: Static tests
              command: PIM_CONTEXT=test make static-back
          - run:
              name: Unit Back
              command: PIM_CONTEXT=test make unit-back
          - run:
              name: Code Coupling Detection
              command: PIM_CONTEXT=test make coupling-back
          - run:
              name: Acceptance tests
              command: PIM_CONTEXT=test make acceptance-back
          - run:
              name: Integration Back
              command: PIM_CONTEXT=test make pim-integration-back
          - run:
              name: End to End Back
              command: PIM_CONTEXT=test make end-to-end-back
          - run:
                name: PhpUnit Migration
                command: PIM_CONTEXT=test make migration-back
          - run:
                name: Tailored Export Back Tests
                command: PIM_CONTEXT=tailored-export make ci-back
          - run:
              name: Tailored Import Back Tests
              command: PIM_CONTEXT=tailored-import make ci-back
          - run:
                name: Install assets & css
                command: make assets css
          - run:
                name: Build the DSM
                command: make dsm
          - run:
                name: Build front-packages
                command: make front-packages
          - run:
                name: Build Javascript
                command: make javascript-test
          - run:
              name: Front linter
              command: PIM_CONTEXT=test make lint-front
          - run:
              name: Front unit tests
              command: PIM_CONTEXT=test make unit-front
          - run:
              name: Tailored Export Front Tests
              command: PIM_CONTEXT=tailored-export make ci-front
          - store_test_results:
                path: ${TYPE}/var/tests
          - store_artifacts:
                path: ${TYPE}/var/tests
          - store_artifacts:
                path: ${TYPE}/var/logs

  test_tria:
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
              at: ~/
          - run:
              name: Define value for next steps
              command: |
                TYPE="tria"
                echo export TYPE=${TYPE} >> $BASH_ENV
          - run:
              name: Setup tests results folder and log folder
              command: mkdir -p ${TYPE}/var/tests/phpspec ${TYPE}/var/tests/csfixer ${TYPE}/var/logs ${TYPE}/var/tests/screenshots ~/.cache/yarn ~/.composer
          - run:
              name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
              command: sudo chown -R 1000:1000 ~/project ~/.cache/yarn ~/.composer
          - run:
              name: Load php image
              command: docker load -i php-pim-image.tar
          - run:
              name: Install dependencies
              command: make dependencies
          - run:
              name: Build the DSM
              command: make dsm
          - run:
              name: Launch Tria in test mode
              command: make pim-test
          - run:
              name: Lint Front
              command: PIM_CONTEXT=test make lint-front
          - run:
              name: Unit Front
              command: PIM_CONTEXT=test make unit-front
          - run:
              name: Lint Back
              command: PIM_CONTEXT=test make lint-back
          - run:
              name: Unit Back
              command: PIM_CONTEXT=test make unit-back
          - run:
              name: Integration Back
              command: PIM_CONTEXT=test make pim-integration-back
          - store_test_results:
              path: ${TYPE}/var/tests
          - store_artifacts:
              path: ${TYPE}/var/tests
          - store_artifacts:
              path: ${TYPE}/var/logs

  pull_request_success:
      docker:
          - image: alpine/git
      resource_class: small
      steps:
          - run:
              name: Success
              command: echo "The build has run with success! Let's merge :)"

  ##################
  # Sanity checks  #
  ##################
  ui_sanity_checks:
      parameters:
        SOURCE_PFID:
          type: string
          default: ""
      machine:
          image: ubuntu-2004:202010-01
      resource_class: large
      steps:
          - attach_workspace:
                at: ~/
          - restore_persisted_env_vars
          - run:
                name: Copy docker-compose.override.yml.dist
                command: cp .circleci/docker-compose.override.yml.dist docker-compose.override.yml
          - run:
                name: Setup tests results folder and log folder
                command: mkdir -p var/tests/phpspec var/tests/csfixer var/logs var/tests/screenshots ~/.cache/yarn ~/.composer ~/.cache/Cypress
          - run:
                name: Modify the password for the sanity check
                command: |
                    sed -i "s/Q7sKB5xP2ttc5KnqFPOF1BrOkTRSulmEj528BpJzbDcLbYSHU1/${PIM_ADMIN_PASSWORD}/g" tests/front/e2e/product/edit.js
          - run:
                name: Change owner on project dir (default user = circleci (1001) and docker needs uid 1000)
                command: |
                    sudo chown -R 1000:1000 ../project
                    sudo chown -R 1000:1000 ~/.composer
                    sudo chown -R 1000:1000 ~/.cache/yarn
                    sudo chown -R 1000:1000 ~/.cache/Cypress
          - run:
                name: Build the latest Docker images
                command: |
                    make php-image-dev
          - when:
                condition:
                    not:
                        equal: [master, << pipeline.git.branch >>]
                steps:
                    - run:
                          name: Update composer.json if same branch exists in CE
                          command: >
                              curl --output /dev/null --silent --head --fail
                              https://github.com/akeneo/pim-community-dev/tree/${CIRCLE_BRANCH} &&
                              docker-compose run --rm -u www-data:www-data php php
                              /usr/local/bin/composer require "akeneo/pim-community-dev:dev-${CIRCLE_BRANCH}" --no-update ||
                              echo "No CE branch $CIRCLE_BRANCH found. I don't touch the composer.json file."
          - run:
                name: Install back dependencies
                command: make dependencies
          - run:
                name: Launch Cypress
                command: |
                    PIM_CONTEXT=test CYPRESS_defaultCommandTimeout=10000 CYPRESS_requestTimeout=10000 CYPRESS_responseTimeout=50000 CYPRESS_baseUrl=https://${INSTANCE_NAME}.dev.cloud.akeneo.com make end-to-end-front
          - store_artifacts:
                path: cypress/screenshots
          - store_artifacts:
                path: cypress/videos
          - store_artifacts:
                path: var/logs

  ##################
  # Helm tests     #
  ##################
  test_helm_generated_k8s_files:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        CLUSTER_VERSION:
          type: string
          default: ""
        CLUSTER_NEXT:
          type: boolean
          default: false
      environment:
        <<: *envVarsDeployDev
      <<: *dockerCloudDeployerNext
      resource_class: small
      steps:
          - attach_workspace:
                at: ~/
          - when:
              condition:
                equal: [true, << parameters.CLUSTER_NEXT >> ]
              steps:
                - modify_cluster
          - set_gcloud_config_dev
          - run:
              name: Define value for next steps
              command: |
                TYPE="<<parameters.PRODUCT_TYPE>>"
                K8S_CLUSTER_VERSION=<< parameters.CLUSTER_VERSION >>

                echo export TYPE=${TYPE} >> $BASH_ENV
                echo export PIM_CONTEXT=${PIM_CONTEXT} >> $BASH_ENV
                echo export K8S_CLUSTER_VERSION=${K8S_CLUSTER_VERSION} >> $BASH_ENV
                echo "K8s version tested (empty=current): ${K8S_CLUSTER_VERSION}"
          - run:
              name: Test <<parameters.PRODUCT_TYPE>> without Onboarder bundle Helm generated yaml files
              command: make -C deployments/ test_helm_generated_k8s_files
          - run:
              name: Test <<parameters.PRODUCT_TYPE>> with Onboarder bundle Helm generated yaml files
              command: WITH_ONBOARDER=1 make -C deployments/ test_helm_generated_k8s_files

  test_cronjobs_existence:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
      environment:
        <<: *envVarsDeployDev
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - set_gcloud_config_dev
          - restore_persisted_env_vars
          - install_yq
          - run:
              name: Test Cronjob jobs exists
              command: make -C deployments/ test-helm-cronjob

  ##################
  # Tests deploy   #
  ##################
  test_deploy:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        CLUSTER_NEXT:
          type: boolean
          default: false
      environment:
        <<: *envVarsDeployDev
      <<: *dockerCloudDeployerNext
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - add_ssh_keys:
                fingerprints:
                    - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
          - when:
              condition:
                equal: [true, << parameters.CLUSTER_NEXT >> ]
              steps:
                - modify_cluster
          - set_gcloud_config_dev
          - restore_persisted_env_vars
          - run:
              name: Define value for next steps
              command: |
                INSTANCE_NAME_PREFIX=pimci
                INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${IMAGE_TAG_SHORTED}-${CIRCLE_BUILD_NUM}

                echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV

                echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                echo "Instance name: ${INSTANCE_NAME}"
                echo "Image tag: ${IMAGE_TAG}"
          - run:
              name: DATADOG deployment Livetail logs page
              command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
          - run:
              name: Deploy PIM on kubernetes
              command: |
                  NS=${TYPE}-${INSTANCE_NAME} PHASE=install bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
                  ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                  export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                  make -C deployments/ deploy-instance
                  make -C deployments/ commit-instance
          - run:
              name: Test PIM connexion on kubernetes
              command: make -C deployments/ test-prod
          - run:
              name: Display Deployment Errors
              command: cat deployment.log
              when: on_fail
          - run:
              name: Prepare infrastructure artifacts
              command: make -C deployments/ prepare-infrastructure-artifacts
              when: on_fail
          - store_artifacts:
              path: ~/artifacts/infra
          - store_artifacts:
              path: deployment.log
              destination: test_deploy_<<parameters.PRODUCT_TYPE>>_deployment.log
          - run:
              name: Remove env on kubernetes
              command: |
                  ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                  export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                  UNCOMMIT_INSTANCE_STATUS_CODE=0
                  for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                  exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
              when: always
          - persist_to_workspace:
              root: ~/
              paths:
                - upgrades.tfplan.json

  test_deploy_last_release:
    parameters:
      PRODUCT_TYPE:
        type: string
        default: "srnt"
      CLUSTER_NEXT:
        type: boolean
        default: false
    environment:
        <<: *envVarsDeployDev
    <<: *dockerCloudDeployerCurrent
    resource_class: medium
    steps:
        - attach_workspace:
              at: ~/
        - add_ssh_keys:
              fingerprints:
                  - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
        - when:
              condition:
                equal: [true, << parameters.CLUSTER_NEXT >> ]
              steps:
                - modify_cluster
        - set_gcloud_config_dev
        - restore_persisted_env_vars
        - run:
              name: Get latest release & export variables
              command: |
                  LATEST_RELEASE=$(bash ${PWD}/deployments/bin/get_latest_release.sh)
                  if [[ -z "${LATEST_RELEASE}" ]]; then
                      echo "Could not retrieve latest deployed release"
                      exit 1
                  fi
                  INSTANCE_NAME_PREFIX=pimup
                  INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${IMAGE_TAG_SHORTED}-${CIRCLE_BUILD_NUM}

                  echo export LATEST_RELEASE=${LATEST_RELEASE} >> $BASH_ENV
                  echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                  echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV

                  echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                  echo "Instance name: ${INSTANCE_NAME}"
                  echo "Image tag: ${IMAGE_TAG}"
                  echo "Latest image tag: ${LATEST_RELEASE}"
        - run:
              name: DATADOG deployment Livetail logs page
              command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
        - run:
              name: Pull Terraform modules from last release
              command: |
                  rm -r ./deployments
                  BOTO_CONFIG=/dev/null gsutil -m cp -r gs://akecld-terraform-modules/${TYPE_LONG}-edition-dev/${LATEST_RELEASE}/deployments/ .
        - run:
              name: Deploy instance with latest release
              command: |
                  ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                  export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                  IMAGE_TAG=${LATEST_RELEASE} make -C deployments/ deploy-instance
                  IMAGE_TAG=${LATEST_RELEASE} make -C deployments/ commit-instance
        - run:
              name: Persist env vars for next jobs
              command: |
                  echo export INSTANCE_NAME="${INSTANCE_NAME}" >> persisted_env_vars
        - run:
            name: Remove env on kubernetes
            command: |
                ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                UNCOMMIT_INSTANCE_STATUS_CODE=0
                for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
            when: on_fail
        - persist_to_workspace:
            root: ~/
            paths:
              - project/persisted_env_vars

  test_upgrade_from_last_release:
    parameters:
      PRODUCT_TYPE:
        type: string
        default: "srnt"
      CLUSTER_NEXT:
        type: boolean
        default: false
    environment:
        <<: *envVarsDeployDev
    <<: *dockerJenkinsCloudDeployer
    resource_class: medium
    steps:
        - attach_workspace:
            at: ~/
        - add_ssh_keys
        - when:
            condition:
              equal: [true, << parameters.CLUSTER_NEXT >> ]
            steps:
              - modify_cluster
        - set_gcloud_config_dev
        - restore_persisted_env_vars
        - run:
            name: Prepare the environment
            command: |
              ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
              echo '' > /root/.ssh/config #clean github exclusions automatically added by circleci
              REPO_TO_ADD=github.com KEY_TO_ADD=/root/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 bash deployments/bin/add-deploy-key.sh
              REPO_TO_ADD=cloud-customers-dev KEY_TO_ADD=/root/.ssh/id_rsa_5f7bb3cbd43de2c2365f9db487865f67 bash deployments/bin/add-deploy-key.sh
              REPO_TO_ADD=jenkins-k8s-utils KEY_TO_ADD=/root/.ssh/id_rsa_2c6118646e36aa7476fd5e6b735923c6 bash deployments/bin/add-deploy-key.sh
              REPO_TO_ADD=operation-tools KEY_TO_ADD=/root/.ssh/id_rsa_9871a29f0e320bbf564ab34189c7b429 bash deployments/bin/add-deploy-key.sh
        - run:
            name: DATADOG deployment Livetail logs page
            command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
        - run:
            name: Jenkins Upgrade
            command: |
              NS=${TYPE}-${INSTANCE_NAME} PHASE=upgrade bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
              OPERATIONS_TOOLS_BRANCH=master make -C deployments/ upgrade-instance
        - run:
            name: Production tests on upgraded env
            command: make -C deployments/ test-prod
        - run:
            name: Check that upgrader pod ran
            command: kubectl get pods --namespace=${TYPE}-${INSTANCE_NAME} | grep pim-upgrader
        - run:
            name: Check PIM version installed
            command: |
              VERSION_INSTALLED=$(helm3 get values ${TYPE}-${INSTANCE_NAME} -n ${TYPE}-${INSTANCE_NAME} | yq r - 'image.pim.tag')
              if [[ "${VERSION_INSTALLED}" == "${IMAGE_TAG}" ]]; then
                echo "PIM successfully upgraded to ${IMAGE_TAG}"
              else
                echo "PIM not upgraded to the correct version"
                echo "PIM version wanted: ${IMAGE_TAG}"
                echo "PIM version installed: ${VERSION_INSTALLED}"
                exit 1
              fi
        - run:
            name: Display Deployment Errors
            command: cat deployment.log
            when: on_fail
        - run:
            name: Check if upgrader failed
            command: kubectl logs -l "job-name=pim-upgrader" --namespace=${TYPE}-${INSTANCE_NAME}
            when: on_fail
        - run:
            name: Prepare infrastructure artifacts
            command: make -C deployments/ prepare-infrastructure-artifacts
            when: on_fail
        - store_artifacts:
            path: ~/artifacts/infra
        - store_artifacts:
            path: deployment.log
            destination: test_upgrade_from_last_release_deployment.log
        - run:
            name: Remove env on kubernetes
            command: |
                ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                UNCOMMIT_INSTANCE_STATUS_CODE=0
                for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
            when: always

  test_clone_from_customer_db:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        SOURCE_PFID:
          type: string
          default: ""
      environment:
          <<: *envVarsDeployDev
      <<: *dockerCloudDeployerNext
      resource_class: small
      steps:
          - attach_workspace:
                at: ~/
          - add_ssh_keys:
                fingerprints:
                    - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
          - set_gcloud_config_dev
          - restore_persisted_env_vars
          - run:
              name: Define value for next steps
              command: |
                SOURCE_PFID=<< parameters.SOURCE_PFID >>
                INSTANCE_NAME_PREFIX=pimci-duplic
                INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-$(echo "${SOURCE_PFID}" | cut -c1-20)-${CIRCLE_BUILD_NUM}

                echo export SOURCE_PFID=${SOURCE_PFID} >> $BASH_ENV
                echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV

                echo "Source PFID: ${SOURCE_PFID}"
                echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                echo "Instance name: ${INSTANCE_NAME}"
                echo "Image tag: ${IMAGE_TAG}"
          - run:
              name: DATADOG deployment Livetail logs page
              command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
          - run:
              name: Duplicate PROD environment
              command: |
                ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                make -C deployments/ clone_saas_instance
                make -C deployments/ commit-instance
          - run:
              name: Persist env vars for next jobs
              command: |
                PIM_ADMIN_PASSWORD=$(yq r /root/project/deployments/instances/${TYPE}-${INSTANCE_NAME}/values.yaml pim.defaultAdminUser.password)
                echo export PIM_ADMIN_PASSWORD=${PIM_ADMIN_PASSWORD} >> persisted_env_vars
                echo export SOURCE_PFID=${SOURCE_PFID} >> persisted_env_vars
                echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> persisted_env_vars
                echo export INSTANCE_NAME=${INSTANCE_NAME} >> persisted_env_vars
          - run:
              name: Prepare infrastructure artifacts
              command: make -C deployments/ prepare-infrastructure-artifacts
              when: on_fail
          - store_artifacts:
              path: ~/artifacts/infra
          - run:
              name: Remove env on kubernetes
              command: |
                  ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                  export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                  UNCOMMIT_INSTANCE_STATUS_CODE=0
                  for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                  exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
              when: on_fail
          - persist_to_workspace:
              root: ~/
              paths:
                - project/persisted_env_vars

  test_clone_from_flex_customer_db:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        SOURCE_PFID_SOURCE_PROJECT_ID:
          type: string
          default: ""
      environment:
          <<: *envVarsDeployDev
      <<: *dockerCloudDeployerNext
      resource_class: small
      steps:
          - attach_workspace:
                at: ~/
          - add_ssh_keys:
                fingerprints:
                    - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
          - set_gcloud_config_dev
          - restore_persisted_env_vars
          - run:
              name: Define value for next steps
              command: |
                SOURCE_PFID_SOURCE_PROJECT_ID=<< parameters.SOURCE_PFID_SOURCE_PROJECT_ID >>
                SOURCE_PFID="${SOURCE_PFID_SOURCE_PROJECT_ID%%##*}"
                SOURCE_PROJECT_ID="${SOURCE_PFID_SOURCE_PROJECT_ID##*##}"
                INSTANCE_NAME_PREFIX=pimci-duplic
                INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-$(echo "${SOURCE_PFID}" | cut -c1-20)-${CIRCLE_BUILD_NUM}
                ACTIVATE_MONITORING=false

                echo export SOURCE_PFID=${SOURCE_PFID} >> $BASH_ENV
                echo export SOURCE_PROJECT_ID=${SOURCE_PROJECT_ID} >> $BASH_ENV
                echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV
                echo export ACTIVATE_MONITORING=${ACTIVATE_MONITORING} >> $BASH_ENV

                echo "Source PFID: ${SOURCE_PFID}"
                echo "Source project ID: ${SOURCE_PROJECT_ID}"
                echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                echo "Instance name: ${INSTANCE_NAME}"
                echo "Image tag: ${IMAGE_TAG}"
          - run:
              name: DATADOG deployment Livetail logs page
              command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
          - run:
              name: Duplicate PROD environment
              command: |
                ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                make -C deployments/ clone_flexibility
                make -C deployments/ commit-instance
          - run:
              name: Prepare infrastructure artifacts
              command: make -C deployments/ prepare-infrastructure-artifacts
              when: on_fail
          - store_artifacts:
              path: ~/artifacts/infra
          - run:
              name: Remove env on kubernetes
              command: |
                  ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                  export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                  make -C deployments/ uncommit-instance
              when: always

  test_upgrade_from_customer_db:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        SOURCE_PFID:
          type: string
          default: ""
      environment:
          <<: *envVarsDeployDev
      <<: *dockerJenkinsCloudDeployer
      resource_class: small
      steps:
          - attach_workspace:
                at: ~/
          - add_ssh_keys
          - set_gcloud_config_dev
          - restore_persisted_env_vars
          - run:
              name: Prepare the environment
              command: |
                ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                echo '' > /root/.ssh/config #clean github exclusions automatically added by circleci
                REPO_TO_ADD=github.com KEY_TO_ADD=/root/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 bash deployments/bin/add-deploy-key.sh
                REPO_TO_ADD=cloud-customers-dev KEY_TO_ADD=/root/.ssh/id_rsa_5f7bb3cbd43de2c2365f9db487865f67 bash deployments/bin/add-deploy-key.sh
                REPO_TO_ADD=jenkins-k8s-utils KEY_TO_ADD=/root/.ssh/id_rsa_2c6118646e36aa7476fd5e6b735923c6 bash deployments/bin/add-deploy-key.sh
                REPO_TO_ADD=operation-tools KEY_TO_ADD=/root/.ssh/id_rsa_9871a29f0e320bbf564ab34189c7b429 bash deployments/bin/add-deploy-key.sh
          - run:
              name: DATADOG deployment Livetail logs page
              command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
          - run:
              name: Jenkins Upgrade
              command: |
                NS=${TYPE}-${INSTANCE_NAME} PHASE=upgrade bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
                OPERATIONS_TOOLS_BRANCH=master make -C deployments/ upgrade-instance
          - run:
              name: Production tests on upgraded env
              command: make -C deployments/ test-prod
          - run:
              name: Check that upgrader pod ran
              command: kubectl get pods --namespace=${TYPE}-${INSTANCE_NAME} | grep pim-upgrader
          - run:
              name: Check PIM version installed
              command: |
                VERSION_INSTALLED=$(helm3 get values ${TYPE}-${INSTANCE_NAME} -n ${TYPE}-${INSTANCE_NAME} | yq r - 'image.pim.tag')
                if [[ "${VERSION_INSTALLED}" == "${IMAGE_TAG}" ]]; then
                  echo "PIM successfully upgraded to ${IMAGE_TAG}"
                else
                  echo "PIM not upgraded to the correct version"
                  echo "PIM version wanted: ${IMAGE_TAG}"
                  echo "PIM version installed: ${VERSION_INSTALLED}"
                  exit 1
                fi
          - run:
              name: Display Deployment Errors
              command: cat deployment.log
              when: on_fail
          - run:
              name: Check if upgrader failed
              command: kubectl logs -l "job-name=pim-upgrader" --namespace=${TYPE}-${INSTANCE_NAME}
              when: on_fail
          - run:
              name: Prepare infrastructure artifacts
              command: make -C deployments/ prepare-infrastructure-artifacts
              when: on_fail
          - store_artifacts:
              path: ~/artifacts/infra
          - store_artifacts:
              path: deployment.log
              destination: test_upgrade_from_srnt_customer_db.log
          - run:
              name: Remove env on kubernetes
              command: |
                  ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                  export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                  UNCOMMIT_INSTANCE_STATUS_CODE=0
                  for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                  exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
              when: on_fail
          - persist_to_workspace:
              root: ~/
              paths:
                - project/persisted_env_vars

  ##################
  # Releases       #
  ##################
  release:
    parameters:
      PRODUCT_TYPE:
        type: string
        default: "srnt"
    environment:
      <<: *envVarsDeployDev
    machine:
      image: ubuntu-2004:202010-01
    resource_class: medium
    steps:
      - attach_workspace:
          at: ~/
      - set_gcloud_config_dev
      - restore_persisted_env_vars
      - run:
          name: Rename release if not on master
          command: |
            if [ "${CIRCLE_BRANCH}" != "master" ]; then
                echo export RELEASE_NAME="RC-${RELEASE_NAME}" >> $BASH_ENV
            fi
      - run:
          name: Push Terraform modules to GCS
          command: |
            BOTO_CONFIG=/dev/null gsutil -m cp -r gs://akecld-terraform-modules/${TYPE_LONG}-edition-dev/${IMAGE_TAG} gs://akecld-terraform-modules/${TYPE_LONG}-edition-dev/${RELEASE_NAME}
            BOTO_CONFIG=/dev/null gsutil -m cp -r gs://akecld-terraform-modules/${TYPE_LONG}-edition-dev/${IMAGE_TAG} gs://akecld-terraform-modules/${TYPE_LONG}-edition/${RELEASE_NAME}
      - run:
          name: Tag the Docker image with the definitive tag
          command: |
            OLD_IMAGE_TAG=${IMAGE_TAG} NEW_IMAGE_TAG=${RELEASE_NAME} make -C deployments/ release
      - run:
          name: Show the definitive tag
          command: |
            echo "RELEASE_NAME=${RELEASE_NAME}"

  ##################
  # Deploy         #
  ##################
  deploy_srnt_helpdesk_environment:
      environment:
        <<: *envVarsDeployPreprod
      <<: *dockerJenkinsCloudDeployer
      resource_class: small
      steps:
            - attach_workspace:
                at: ~/
            - set_gcloud_config_preprod
            - add_ssh_keys
            - run:
                name: Define value for next steps
                command: |
                  TYPE="srnt"
                  RELEASE_TO_DEPLOY=$(gcloud container images list-tags eu.gcr.io/akeneo-cloud/pim-enterprise-dev --filter="tags~^v[0-9]{14}$" --sort-by="~tags" --limit=1 --format="value(tags)")
                  INSTANCE_NAME="pimci-helpdesk"
                  PRODUCT_REFERENCE_TYPE="serenity_instance"
                  PRODUCT_REFERENCE_CODE="serenity_${ENV_NAME}"
                  ACTIVATE_MONITORING=true

                  echo export TYPE=${TYPE} >> $BASH_ENV
                  echo export RELEASE_TO_DEPLOY=${RELEASE_TO_DEPLOY} >> $BASH_ENV
                  echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV
                  echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
                  echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV
                  echo export ACTIVATE_MONITORING=${ACTIVATE_MONITORING} >> $BASH_ENV

                  echo "Instance name: ${INSTANCE_NAME}"
                  echo "Release to deploy: ${RELEASE_TO_DEPLOY}"
            - run:
                name: DATADOG deployment Livetail logs page
                command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
            - run:
                name: Setup key for Jenkins
                command: |
                  ssh-keyscan github.com >> ~/.ssh/known_hosts
                  echo '' > /root/.ssh/config #clean github exclusions automatically added by circleci
                  REPO_TO_ADD=github.com KEY_TO_ADD=/root/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 bash deployments/bin/add-deploy-key.sh
                  REPO_TO_ADD=cloud-customers-dev KEY_TO_ADD=/root/.ssh/id_rsa_5f7bb3cbd43de2c2365f9db487865f67 bash deployments/bin/add-deploy-key.sh
                  REPO_TO_ADD=jenkins-k8s-utils KEY_TO_ADD=/root/.ssh/id_rsa_2c6118646e36aa7476fd5e6b735923c6 bash deployments/bin/add-deploy-key.sh
                  REPO_TO_ADD=operation-tools KEY_TO_ADD=/root/.ssh/id_rsa_9871a29f0e320bbf564ab34189c7b429 bash deployments/bin/add-deploy-key.sh
            - run:
                name: Jenkins Upgrade
                command: IMAGE_TAG=${RELEASE_TO_DEPLOY} OPERATIONS_TOOLS_BRANCH=master make -C deployments/ upgrade-instance
            - run:
                name: Communicate
                command: |
                  IMAGE_TAG=${RELEASE_TO_DEPLOY} make -C deployments/ slack_helpdesk

  deploy_grth_helpdesk_environment:
      environment:
        <<: *envVarsDeployPreprod
      <<: *dockerJenkinsCloudDeployer
      resource_class: small
      steps:
            - attach_workspace:
                at: ~/
            - set_gcloud_config_preprod
            - add_ssh_keys
            - run:
                name: Define value for next steps
                command: |
                  TYPE="grth"
                  RELEASE_TO_DEPLOY=$(gcloud container images list-tags eu.gcr.io/akeneo-cloud/pim-enterprise-dev --filter="tags~^growth-v[0-9]{14}$" --sort-by="~tags" --limit=1 --format="value(tags)")
                  INSTANCE_NAME="pimci-helpdesk-ge"
                  PRODUCT_REFERENCE_TYPE="growth_edition_instance"
                  PRODUCT_REFERENCE_CODE="growth_edition_${ENV_NAME}"
                  ACTIVATE_MONITORING=true

                  echo export TYPE=${TYPE} >> $BASH_ENV
                  echo export RELEASE_TO_DEPLOY=${RELEASE_TO_DEPLOY} >> $BASH_ENV
                  echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV
                  echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
                  echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV
                  echo export ACTIVATE_MONITORING=${ACTIVATE_MONITORING} >> $BASH_ENV
                  echo "Instance name: ${INSTANCE_NAME}"
                  echo "Image tag: ${IMAGE_TAG}"
                  echo "Release to deploy: ${RELEASE_TO_DEPLOY}"
            - run:
                name: DATADOG deployment Livetail logs page
                command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
            - run:
                name: Setup key for Jenkins
                command: |
                  ssh-keyscan github.com >> ~/.ssh/known_hosts
                  echo '' > /root/.ssh/config #clean github exclusions automatically added by circleci
                  REPO_TO_ADD=github.com KEY_TO_ADD=/root/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 bash deployments/bin/add-deploy-key.sh
                  REPO_TO_ADD=cloud-customers-dev KEY_TO_ADD=/root/.ssh/id_rsa_5f7bb3cbd43de2c2365f9db487865f67 bash deployments/bin/add-deploy-key.sh
                  REPO_TO_ADD=jenkins-k8s-utils KEY_TO_ADD=/root/.ssh/id_rsa_2c6118646e36aa7476fd5e6b735923c6 bash deployments/bin/add-deploy-key.sh
                  REPO_TO_ADD=operation-tools KEY_TO_ADD=/root/.ssh/id_rsa_9871a29f0e320bbf564ab34189c7b429 bash deployments/bin/add-deploy-key.sh
            - run:
                  name: Jenkins Upgrade
                  command: IMAGE_TAG=${RELEASE_TO_DEPLOY} OPERATIONS_TOOLS_BRANCH=master make -C deployments/ upgrade-instance
            - run:
                name: Communicate
                command: |
                    IMAGE_TAG=${RELEASE_TO_DEPLOY} make -C deployments/ slack_helpdesk

  deploy_pm_environment:
      environment:
          <<: *envVarsDeployPreprod
      <<: *dockerJenkinsCloudDeployer
      resource_class: small
      steps:
          - attach_workspace:
                at: ~/
          - set_gcloud_config_preprod
          - add_ssh_keys
          - run:
              name: Define value for next steps
              command: |
                TYPE="srnt"
                RELEASE_TO_DEPLOY=$(gcloud container images list-tags eu.gcr.io/akeneo-cloud/pim-enterprise-dev --filter="tags~^v[0-9]{14}$" --sort-by="~tags" --limit=1 --format="value(tags)")
                INSTANCE_NAME="pimci-pm"
                PRODUCT_REFERENCE_TYPE="serenity_instance"
                PRODUCT_REFERENCE_CODE="serenity_${ENV_NAME}"
                ACTIVATE_MONITORING=true

                echo export TYPE=${TYPE} >> $BASH_ENV
                echo export RELEASE_TO_DEPLOY=${RELEASE_TO_DEPLOY} >> $BASH_ENV
                echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV
                echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
                echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV
                echo export ACTIVATE_MONITORING=${ACTIVATE_MONITORING} >> $BASH_ENV

                echo "Instance name: ${INSTANCE_NAME}"
                echo "Release to deploy: ${RELEASE_TO_DEPLOY}"
          - run:
              name: DATADOG deployment Livetail logs page
              command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
          - run:
              name: Setup key for Jenkins
              command: |
                ssh-keyscan github.com >> ~/.ssh/known_hosts
                echo '' > /root/.ssh/config #clean github exclusions automatically added by circleci
                REPO_TO_ADD=github.com KEY_TO_ADD=/root/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 bash deployments/bin/add-deploy-key.sh
                REPO_TO_ADD=cloud-customers-dev KEY_TO_ADD=/root/.ssh/id_rsa_5f7bb3cbd43de2c2365f9db487865f67 bash deployments/bin/add-deploy-key.sh
                REPO_TO_ADD=jenkins-k8s-utils KEY_TO_ADD=/root/.ssh/id_rsa_2c6118646e36aa7476fd5e6b735923c6 bash deployments/bin/add-deploy-key.sh
                REPO_TO_ADD=operation-tools KEY_TO_ADD=/root/.ssh/id_rsa_9871a29f0e320bbf564ab34189c7b429 bash deployments/bin/add-deploy-key.sh
          - run:
              name: Jenkins Upgrade
              command: IMAGE_TAG=${RELEASE_TO_DEPLOY} OPERATIONS_TOOLS_BRANCH=master make -C deployments/ upgrade-instance

  deploy_pr_environment:
    parameters:
      PRODUCT_TYPE:
        type: string
        default: "srnt"
    environment:
        <<: *envVarsDeployDev
    <<: *dockerCloudDeployerNext
    resource_class: small
    steps:
      - attach_workspace:
          at: ~/
      - add_ssh_keys:
                fingerprints:
                    - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
      - set_gcloud_config_dev
      - restore_persisted_env_vars
      - run:
          name: Define value for next steps
          command: |
            TYPE="<<parameters.PRODUCT_TYPE>>"
            INSTANCE_NAME_PREFIX=pimci-pr
            if [[ "${TYPE}" == "grth" ]]; then
                INSTANCE_NAME_PREFIX=pimci-pr-ge
            fi
            if [[ "${TYPE}" == "tria" ]]; then
                INSTANCE_NAME_PREFIX=pimci-pr-ft
            fi
            INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${CIRCLE_PULL_REQUEST##*/}
            ACTIVATE_MONITORING=true

            echo export IMAGE_TAG=${IMAGE_TAG} >> $BASH_ENV
            echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
            echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV
            echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
            echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV
            echo export ACTIVATE_MONITORING=${ACTIVATE_MONITORING} >> $BASH_ENV

            echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
            echo "Instance name: ${INSTANCE_NAME}"
            echo "Image tag: ${IMAGE_TAG}"
      - run:
          name: DATADOG deployment Livetail logs page
          command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TYPE}-${INSTANCE_NAME}"
      - run:
          name: Check Circle CI PR
          command: |
            if [[ ${CIRCLE_PULL_REQUEST##*/} == "" ]]; then echo "ERROR : CIRCLE_PULL_REQUEST is empty."; exit 1;fi
            echo "This environment will be available at https://${INSTANCE_NAME}.dev.cloud.akeneo.com once deployed :)"
      - run:
          name: Deploy PR environment
          command: |
            NS=${TYPE}-${INSTANCE_NAME} PHASE=install bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
            ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
            export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
            make -C deployments/ deploy-instance
            make -C deployments/ commit-instance
      - run:
          name: Persist env vars for next jobs
          command: |
            echo export INSTANCE_NAME="${INSTANCE_NAME}" >> persisted_env_vars
            echo export INSTANCE_NAME_PREFIX="${INSTANCE_NAME_PREFIX}" >> persisted_env_vars
      - persist_to_workspace:
          root: ~/
          paths:
            - project/persisted_env_vars
      - run:
          name: Prepare infrastructure artifacts
          command: make -C deployments/ prepare-infrastructure-artifacts
          when: on_fail
      - run:
          name: Remove env on kubernetes
          command: |
              ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
              export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
              UNCOMMIT_INSTANCE_STATUS_CODE=0
              for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
              exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
          when: on_fail
      - store_artifacts:
          path: ~/artifacts/infra

  ##################
  # Cleanup        #
  ##################
  delete_environments_hourly:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: ""
      environment:
          <<: *envVarsDeployDev
      <<: *dockerCloudDeployerNext
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - add_ssh_keys:
                fingerprints:
                    - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
          - set_gcloud_config_dev
          - run:
                name: Delete environments
                no_output_timeout: 30m
                command: |
                    TYPE="<<parameters.PRODUCT_TYPE>>"
                    ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts

                    export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'

                    TYPE=${TYPE} make -C deployments/ delete_environments_hourly

  delete_pr_environment:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: ""
      environment:
          <<: *envVarsDeployDev
      <<: *dockerCloudDeployerNext
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - add_ssh_keys:
                fingerprints:
                    - "5f:7b:b3:cb:d4:3d:e2:c2:36:5f:9d:b4:87:86:5f:67"
                    - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
          - set_gcloud_config_dev
          - restore_persisted_env_vars
          - run:
                name: Delete environments
                no_output_timeout: 30m
                command: |
                    ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                    export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_5f7bb3cbd43de2c2365f9db487865f67 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                    UNCOMMIT_INSTANCE_STATUS_CODE=0
                    for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                    exit ${UNCOMMIT_INSTANCE_STATUS_CODE}


  delete_expired_uptime_check:
      environment:
          <<: *envVarsDeployDev
      machine:
          image: ubuntu-1604:201903-01
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - set_gcloud_config_dev
          - run:
                name: Delete expired uptime checks
                command:
                    make -C deployments/ delete_expired_uptime_check

  remove_unused_resources:
      environment:
          <<: *envVarsDeployDev
      <<: *dockerCloudDeployerNext
      resource_class: small
      steps:
          - attach_workspace:
                at: ~/
          - set_gcloud_config_dev
          - run:
                name: Remove unused resources
                command:
                    make -C deployments/ remove_unused_resources

  #########################
  # Deployment validation #
  #########################
  zdd_compliancy_diff:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        CHECK_AGAINST:
          type: string
          default: "top"
      environment:
          <<: *envVarsDeployDev
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - checkout
          - set_gcloud_config_dev
          - run:
                name: Run the tool zdd_compliancy_checker
                command: |
                    OPTIONS=""
                    if [ "<< parameters.CHECK_AGAINST >>" == "oldest" ]; then
                        OPTIONS="-o"
                    fi
                    VERSIONS_FILE=/tmp/zdd_versions.env
                    touch ${VERSIONS_FILE}
                    VERSIONS_FILE=${VERSIONS_FILE} TYPE=<<parameters.PRODUCT_TYPE>> bash deployments/bin/zdd_compliancy_checker.sh ${OPTIONS}
          - store_artifacts:
              path: /tmp/zdd_versions.env
              destination: versions
          - persist_to_workspace:
              root: ~/
              paths:
                - zdd_compliancy_checker

  zdd_compliancy_checker:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        CONTEXT:
          type: string
          default: "diff_infra"
      machine:
          image: ubuntu-2004:202010-01
      resource_class: medium
      steps:
          - attach_workspace:
                at: ~/
          - checkout
          - run:
                name: Run the tool zdd_compliancy_checker
                command:
                    TYPE=<<parameters.PRODUCT_TYPE>> ZCC_CONTEXT=diff_<<parameters.CONTEXT>> bash deployments/bin/zdd_compliancy_checker.sh

  post_deployment_e2e_validation:
      parameters:
        PRODUCT_TYPE:
          type: string
          default: "srnt"
        PFID:
          type: string
          default: "srnt-c3po"
      machine:
          image: ubuntu-2004:202010-01
      resource_class: large
      steps:
          - attach_workspace:
                at: ~/
          - checkout
          - install_yq
          - run:
                name: Run demo deployment with e2e test
                command: |
                    CURRENT_TIME=$(date +%s)
                    LAST_HOUR_TIME=$(( CURRENT_TIME - 60*60 ))
                    VERSION=$(curl --location -s -g -H "Content-Type: application/json" -H "DD-API-KEY: ${DATADOG_API_KEY}" -H "DD-APPLICATION-KEY: ${DATADOG_APP_KEY}" --request GET "https://api.datadoghq.eu/api/v1/query?from=${LAST_HOUR_TIME}&to=${CURRENT_TIME}&query=sum:kubernetes.containers.running{project:akecld-saas-demo,short_image:pim-enterprise-dev,app:pim,component:pim-web,type:<<parameters.PRODUCT_TYPE>>,pfid:<<parameters.PFID>>}%20by%20{image_tag}" | yq r - 'series[*].tag_set[0]' | sort | tail -n1 | cut -c11-)
                    TYPE=<<parameters.PRODUCT_TYPE>> LOGIN=${E2E_LOGIN_<<parameters.PRODUCT_TYPE>>} PASSWORD=${E2E_PASSWORD_<<parameters.PRODUCT_TYPE>>} VERSION=${VERSION} make -C deployments/ test_deployment_e2e
          - store_artifacts:
                path: deployments/test/e2e/cypress/screenshots/
          - store_artifacts:
                path: deployments/test/e2e/cypress/videos/

  list_production_version:
    parameters:
        PRODUCT_TYPE:
            type: string
            default: "srnt"
    docker:
        - image: cimg/base:2021.12
    resource_class: small
    steps:
          - run:
                name: Versions in production
                command: |
                    CURRENT_TIME=$(date +%s)
                    LAST_HOUR_TIME=$(( CURRENT_TIME - 60*60 ))
                    curl --location -s -g -H "Content-Type: application/json" -H "DD-API-KEY: ${DATADOG_API_KEY}" -H "DD-APPLICATION-KEY: ${DATADOG_APP_KEY}" --request GET "https://api.datadoghq.eu/api/v1/query?from=${LAST_HOUR_TIME}&to=${CURRENT_TIME}&query=top(sum:kubernetes.containers.running{project:akecld-saas-prod,short_image:pim-enterprise-dev,app:pim,component:pim-web,type:<<parameters.PRODUCT_TYPE>>}by{image_tag},%20100,%20%27max%27,%20%27desc%27)" | jq -r .series[].tag_set[0] | cut -c11- | sort

workflows:
  pull_request:
      when:
          not:
              equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
      jobs:
          - ready_to_build?:
                type: approval
                filters:
                    branches:
                        ignore:
                            - "master"
          - checkout:
                requires:
                    - ready_to_build?
          - test_helm_generated_k8s_files:
                name: "[<< matrix.PRODUCT_TYPE >>] Test helm generated k8s files"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth", "tria"]
                requires:
                    - checkout
          - build_srnt_prod:
                name: "[srnt] Build"
                requires:
                    - "[srnt] Test helm generated k8s files"
          - build_grth:
                name: "[grth] Build"
                requires:
                    - "[grth] Test helm generated k8s files"
          - build_tria:
                name: "[tria] Build"
                requires:
                    - "[tria] Test helm generated k8s files"
          - test_cronjobs_existence:
                name: "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth", "tria"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] Build"
          - test_deploy:
                name: "[<< matrix.PRODUCT_TYPE >>] Test deploy"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth", "tria"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
          - test_deploy_last_release:
                name: "[<< matrix.PRODUCT_TYPE >>] Test deploy last release"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
          - test_upgrade_from_last_release:
                name: "[<< matrix.PRODUCT_TYPE >>] Test upgrade from last release"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] Test deploy last release"
          - deploy_pr_environment?:
                name: "[<< matrix.PRODUCT_TYPE >>] Deploy PR environment?"
                type: approval
                filters:
                    branches:
                        ignore:
                            - "master"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth", "tria"]
          - deploy_pr_environment:
                name: "[<< matrix.PRODUCT_TYPE >>] Deploy PR environment"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth", "tria"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] Deploy PR environment?"
                    - "[<< matrix.PRODUCT_TYPE >>] Build"
          - delete_pr_environment?:
                name: "[<< matrix.PRODUCT_TYPE >>] Delete PR environment?"
                type: approval
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth", "tria"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] Deploy PR environment"
          - delete_pr_environment:
                name: "[<< matrix.PRODUCT_TYPE >>] Delete PR environment"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt", "grth", "tria"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] Delete PR environment?"
          - build_srnt_dev:
                requires:
                    - checkout
          - test_back_integration_bounded_contexts:
                requires:
                    - build_srnt_dev
          - test_back_integration_reference_entities:
                requires:
                    - build_srnt_dev
          - test_back_static_and_acceptance:
                requires:
                    - build_srnt_dev
          - test_back_phpunit:
                requires:
                    - build_srnt_dev
          - test_back_performance:
                requires:
                    - build_srnt_dev
          - test_back_data_migrations:
                requires:
                    - build_srnt_dev
          - test_front_static_acceptance_and_integration:
                requires:
                    - build_srnt_dev
          - test_front_end_to_end:
                requires:
                    - build_srnt_dev
          - test_front_code_style:
                requires:
                    - build_srnt_dev
          - test_back_behat_legacy:
                requires:
                    - test_back_static_and_acceptance
                    - test_front_static_acceptance_and_integration
                    - test_front_code_style
                    - test_back_phpunit
                    - test_back_integration_bounded_contexts
                    - test_back_integration_reference_entities
          - test_database:
                requires:
                    - build_srnt_dev
          - test_onboarder_bundle:
                requires:
                    - build_srnt_dev
          - test_grth:
                requires:
                    - build_srnt_dev
          - test_tria:
                requires:
                    - build_srnt_dev
          - pull_request_success:
                requires:
                    - test_back_performance
                    - test_back_behat_legacy
                    - test_onboarder_bundle
                    - test_database
                    - test_back_data_migrations
                    - test_grth
                    - test_tria

  on_demand_deployment_validation:
    when:
        not:
            equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
    jobs:
      - deployment_validation:
          name: "Start test ?"
          type: approval
          filters:
            branches:
              only:
                - master
      - checkout:
          requires:
            - "Start test ?"
      - post_deployment_e2e_validation:
          name: "[srnt] Post deployment e2e validation"
          requires:
            - "checkout"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt"]
              PFID: ["srnt-c3po"]
      - post_deployment_e2e_validation:
          name: "[grth] Post deployment e2e validation"
          requires:
            - "checkout"
          matrix:
            parameters:
              PRODUCT_TYPE: ["grth"]
              PFID: ["grth-r2d2"]

  on_demand_release:
    when:
        not:
            equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
    jobs:
      - ready_to_build?:
          name: "[<< matrix.PRODUCT_TYPE >>] Release ?"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt", "grth", "tria"]
          type: approval
          filters:
            branches:
              only:
                 - master
      - checkout:
          name: "[<< matrix.PRODUCT_TYPE >>] Checkout"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt", "grth", "tria"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Release ?"
      - build_srnt_dev:
          name: "[srnt] Build dev"
          requires:
            - "[srnt] Checkout"
      - build_srnt_prod:
          name: "[srnt] Build prod"
          requires:
            - "[srnt] Checkout"
      - build_grth:
          name: "[grth] Build prod"
          requires:
            - "[grth] Checkout"
      - build_tria:
          name: "[tria] Build prod"
          requires:
            - "[tria] Checkout"
      - test_front_code_style:
          requires:
            - "[srnt] Build dev"
      - test_back_static_and_acceptance:
          requires:
            - "[srnt] Build dev"
      - test_front_static_acceptance_and_integration:
          requires:
            - "[srnt] Build dev"
      - test_back_phpunit:
          requires:
            - "[srnt] Build dev"
      - test_back_integration_bounded_contexts:
          requires:
            - "[srnt] Build dev"
      - test_back_integration_reference_entities:
          requires:
            - "[srnt] Build dev"
      - test_back_performance:
          requires:
            - "[srnt] Build dev"
      - test_onboarder_bundle:
          requires:
            - "[srnt] Build dev"
      - test_back_behat_legacy:
          requires:
            - "[srnt] Build dev"
      - test_back_data_migrations:
          requires:
            - "[srnt] Build dev"
      - test_cronjobs_existence:
          name: "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt", "grth", "tria"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Build prod"
      - test_deploy:
          name: "[<< matrix.PRODUCT_TYPE >>] Test deploy"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt", "grth", "tria"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
      - test_deploy_last_release:
          name: "[<< matrix.PRODUCT_TYPE >>] Test deploy last release"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt", "grth"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
      - test_upgrade_from_last_release:
          name: "[<< matrix.PRODUCT_TYPE >>] Test upgrade from last release"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt", "grth"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test deploy last release"
      - release:
          name: "[<< matrix.PRODUCT_TYPE >>] Release"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test deploy"
            - "[<< matrix.PRODUCT_TYPE >>] Test upgrade from last release"
            - test_back_static_and_acceptance
            - test_front_static_acceptance_and_integration
            - test_back_phpunit
            - test_back_integration_bounded_contexts
            - test_back_integration_reference_entities
            - test_onboarder_bundle
            - test_back_performance
            - test_back_behat_legacy
            - test_back_data_migrations
      - release:
          name: "[<< matrix.PRODUCT_TYPE >>] Release"
          matrix:
            parameters:
              PRODUCT_TYPE: ["grth"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test deploy"
            - "[<< matrix.PRODUCT_TYPE >>] Test upgrade from last release"
      - release:
          name: "[<< matrix.PRODUCT_TYPE >>] Release"
          matrix:
            parameters:
              PRODUCT_TYPE: ["tria"]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test deploy"

  nightly_srnt_release:
      when:
          and:
              - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
              - equal: [ "nightly_srnt_release", << pipeline.schedule.name >> ]
      jobs:
          - checkout
          - build_srnt_prod:
                <<: *slack-fail-post-step
                requires:
                    - checkout
          - build_srnt_dev:
                <<: *slack-fail-post-step
                requires:
                    - checkout
          - test_cronjobs_existence:
                <<: *slack-fail-post-step
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                requires:
                    - build_srnt_prod
          - test_deploy:
                <<: *slack-fail-post-step
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                requires:
                    - test_cronjobs_existence
          - test_deploy_last_release:
                <<: *slack-fail-post-step
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                requires:
                    - test_cronjobs_existence
          - test_upgrade_from_last_release:
                <<: *slack-fail-post-step
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                requires:
                    - test_deploy_last_release
          - test_front_code_style:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_back_static_and_acceptance:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_front_static_acceptance_and_integration:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_back_phpunit:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_back_integration_bounded_contexts:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_back_integration_reference_entities:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_back_performance:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_onboarder_bundle:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_back_behat_legacy:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - test_back_data_migrations:
                <<: *slack-fail-post-step
                requires:
                    - build_srnt_dev
          - release:
                <<: *slack-post-step
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                requires:
                    - test_back_static_and_acceptance
                    - test_front_static_acceptance_and_integration
                    - test_back_phpunit
                    - test_back_integration_bounded_contexts
                    - test_back_integration_reference_entities
                    - test_onboarder_bundle
                    - test_back_performance
                    - test_back_behat_legacy
                    - test_back_data_migrations
                    - test_deploy
                    - test_upgrade_from_last_release

  nightly_grth_release:
      when:
          and:
              - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
              - equal: [ "nightly_grth_release", << pipeline.schedule.name >> ]
      jobs:
          - checkout
          - build_grth:
                <<: *slack-fail-post-step
                requires:
                    - checkout
          - test_cronjobs_existence:
                <<: *slack-fail-post-step
                matrix:
                  parameters:
                    PRODUCT_TYPE: ["grth"]
                requires:
                    - build_grth
          - test_deploy:
                <<: *slack-fail-post-step
                matrix:
                  parameters:
                    PRODUCT_TYPE: ["grth"]
                requires:
                    - test_cronjobs_existence
          - test_deploy_last_release:
                <<: *slack-fail-post-step
                matrix:
                  parameters:
                    PRODUCT_TYPE: ["grth"]
                requires:
                    - test_cronjobs_existence
          - test_upgrade_from_last_release:
                <<: *slack-fail-post-step
                matrix:
                  parameters:
                    PRODUCT_TYPE: ["grth"]
                requires:
                    - test_deploy_last_release
          - release:
                <<: *slack-post-step
                matrix:
                  parameters:
                    PRODUCT_TYPE: ["grth"]
                requires:
                    - test_deploy
                    - test_upgrade_from_last_release

  nightly_tria_release:
    when:
        and:
            - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
            - equal: [ "nightly_tria_release", << pipeline.schedule.name >> ]
    jobs:
      - checkout
      - build_tria:
          <<: *slack-fail-post-step
          requires:
            - checkout
      - test_cronjobs_existence:
          <<: *slack-fail-post-step
          matrix:
            parameters:
              PRODUCT_TYPE: ["tria"]
          requires:
            - build_tria
      - test_deploy:
          <<: *slack-fail-post-step
          matrix:
            parameters:
              PRODUCT_TYPE: ["tria"]
          requires:
            - test_cronjobs_existence
      - release:
          <<: *slack-post-step
          matrix:
            parameters:
              PRODUCT_TYPE: ["tria"]
          requires:
            - test_deploy

  nightly_deployments:
      when:
          and:
              - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
              - equal: [ "nightly_deployments", << pipeline.schedule.name >> ]
      jobs:
          - checkout
          - deploy_srnt_helpdesk_environment:
                requires:
                    - checkout
          - deploy_grth_helpdesk_environment:
                requires:
                    - checkout
          - deploy_pm_environment:
                requires:
                    - checkout

  nightly_beta:
      when:
          and:
              - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
              - equal: [ "nightly_beta", << pipeline.schedule.name >> ]
      jobs:
          - checkout
          - test_helm_generated_k8s_files:
                name: "[<< matrix.PRODUCT_TYPE >>][<< matrix.CLUSTER_VERSION >>] Test helm generated k8s files"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                        CLUSTER_VERSION: ["1.19.0", "1.20.0", "1.21.0", "1.22.0"]
                requires:
                    - checkout
          - build_srnt_prod:
                requires:
                    - checkout
          - test_clone_from_flex_customer_db:
                name: "[<< matrix.PRODUCT_TYPE >>] test_clone_from-<< matrix.SOURCE_PFID_SOURCE_PROJECT_ID >>"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["flex"]
                        SOURCE_PFID_SOURCE_PROJECT_ID: ["assa-abloy-dev##akecld-assa-abloy", "curacao-production##akecld-curacao-pim"]
                requires:
                    - build_srnt_prod
          - test_clone_from_customer_db:
                name: "[<< matrix.PRODUCT_TYPE >>] test_clone_from-<< matrix.SOURCE_PFID >>"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                        SOURCE_PFID: ["srnt-madeira-production", "srnt-petra", "srnt-rdoequipment-prod", "srnt-electrodepot", "srnt-distributionnow-prod"]
                requires:
                    - build_srnt_prod
          - test_upgrade_from_customer_db:
                name: "[<< matrix.PRODUCT_TYPE >>] test_upgrade_from-<< matrix.SOURCE_PFID >>"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["srnt"]
                        SOURCE_PFID: ["srnt-madeira-production", "srnt-petra", "srnt-rdoequipment-prod", "srnt-electrodepot", "srnt-distributionnow-prod"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] test_clone_from-<< matrix.SOURCE_PFID >>"
          - ui_sanity_checks:
                name: sanity_checks-<< matrix.SOURCE_PFID >>
                matrix:
                    parameters:
                        SOURCE_PFID: ["srnt-madeira-production", "srnt-petra", "srnt-rdoequipment-prod", "srnt-electrodepot", "srnt-distributionnow-prod"]
                requires:
                    - "[srnt] test_upgrade_from-<< matrix.SOURCE_PFID >>"
          - build_grth:
                requires:
                    - checkout
          - test_clone_from_customer_db:
                name: "[<< matrix.PRODUCT_TYPE >>] test_clone_from-<< matrix.SOURCE_PFID >>"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["grth"]
                        SOURCE_PFID: ["grth-sirius-staging"]
                requires:
                    - build_grth
          - test_upgrade_from_customer_db:
                name: "[<< matrix.PRODUCT_TYPE >>] test_upgrade_from-<< matrix.SOURCE_PFID >>"
                matrix:
                    parameters:
                        PRODUCT_TYPE: ["grth"]
                        SOURCE_PFID: ["grth-sirius-staging"]
                requires:
                    - "[<< matrix.PRODUCT_TYPE >>] test_clone_from-<< matrix.SOURCE_PFID >>"

  nightly_next_cluster:
    when:
        and:
            - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
            - equal: [ "nightly_next_cluster", << pipeline.schedule.name >> ]
    jobs:
      - checkout
      - test_helm_generated_k8s_files:
          name: "[<< matrix.PRODUCT_TYPE >>] Test helm generated k8s files"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt"]
              CLUSTER_NEXT: [true]
          requires:
            - checkout
      - build_srnt_prod:
          requires:
            - "[srnt] Test helm generated k8s files"
      - test_cronjobs_existence:
          name: "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt"]
          requires:
            - build_srnt_prod
      - test_deploy:
          name: "[<< matrix.PRODUCT_TYPE >>] Test deploy"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt"]
              CLUSTER_NEXT: [true]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
      - test_deploy_last_release:
          name: "[<< matrix.PRODUCT_TYPE >>] Test deploy last release"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt"]
              CLUSTER_NEXT: [true]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test cronjobs existence"
      - test_upgrade_from_last_release:
          name: "[<< matrix.PRODUCT_TYPE >>] Test upgrade from last release"
          matrix:
            parameters:
              PRODUCT_TYPE: ["srnt"]
              CLUSTER_NEXT: [true]
          requires:
            - "[<< matrix.PRODUCT_TYPE >>] Test deploy last release"

  hourly_cleanup:
     when:
         and:
             - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
             - equal: [ "hourly_cleanup", << pipeline.schedule.name >> ]
     jobs:
         - checkout
         - delete_environments_hourly:
             name: "[<< matrix.PRODUCT_TYPE >>] Delete environments"
             matrix:
               parameters:
                 PRODUCT_TYPE: ["srnt", "grth", "tria"]
             requires:
               - checkout
         - remove_unused_resources:
             requires:
               - checkout
         - delete_expired_uptime_check:
             requires:
               - checkout

  on_demand_compliancy_checker:
    when:
        not:
            equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
    jobs:
        - ready_to_build?:
            type: approval
            filters:
              branches:
                only:
                    - master
        - zdd_compliancy_diff:
            name: "[<< matrix.PRODUCT_TYPE >>][top] Get ZDD compliancy files"
            matrix:
                parameters:
                    PRODUCT_TYPE: ["grth", "srnt"]
                    CHECK_AGAINST: ["top"]
            requires:
                - ready_to_build?
        - zdd_compliancy_checker:
            name: "[<< matrix.PRODUCT_TYPE >>][top][<< matrix.CONTEXT >>] Check ZDD compliancy"
            matrix:
                parameters:
                    PRODUCT_TYPE: ["grth", "srnt"]
                    CONTEXT: ["infra", "db"]
            requires:
                - "[<< matrix.PRODUCT_TYPE >>][top] Get ZDD compliancy files"
        - list_production_version:
            name: "[<< matrix.PRODUCT_TYPE >>] Versions currently in production"
            matrix:
                parameters:
                    PRODUCT_TYPE: ["grth", "srnt"]
            requires:
                - ready_to_build?
        - execute_compliancy_check:
            type: approval
            name: "[<< matrix.PRODUCT_TYPE >>] Execute compliancy check on oldest version"
            matrix:
                parameters:
                    PRODUCT_TYPE: ["grth", "srnt"]
            requires:
                - "[<< matrix.PRODUCT_TYPE >>] Versions currently in production"
        - zdd_compliancy_diff:
            name: "[<< matrix.PRODUCT_TYPE >>][<< matrix.CHECK_AGAINST >>] Get ZDD compliancy files"
            matrix:
                parameters:
                    PRODUCT_TYPE: ["grth", "srnt"]
                    CHECK_AGAINST: ["oldest"]
            requires:
                - "[<< matrix.PRODUCT_TYPE >>] Execute compliancy check on oldest version"
        - zdd_compliancy_checker:
            name: "[<< matrix.PRODUCT_TYPE >>][oldest][<< matrix.CONTEXT >>] Check ZDD compliancy"
            matrix:
                parameters:
                    PRODUCT_TYPE: ["grth", "srnt"]
                    CONTEXT: ["infra", "db"]
            requires:
                - "[<< matrix.PRODUCT_TYPE >>][oldest] Get ZDD compliancy files"

commands:
  set_gcloud_config_dev:
    description: "Authenticate on GCP services and set config and key to be used by other tools that need to authenticate."
    steps:
      - run:
          name: "Set Gcloud Config."
          shell: "/bin/bash -eo pipefail"
          command: |
            echo ${GCLOUD_SERVICE_KEY_DEV} | gcloud auth activate-service-account --key-file=-
            gcloud config set project ${GOOGLE_PROJECT_ID}
            gcloud config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud container clusters get-credentials ${GOOGLE_COMPUTE_ZONE} --project=${GOOGLE_PROJECT_ID} --zone=${GOOGLE_COMPUTE_ZONE}
            echo ${GCLOUD_SERVICE_KEY_DEV} > ${HOME}/gcloud-service-key.json
            echo 'export GOOGLE_APPLICATION_CREDENTIALS="${HOME}/gcloud-service-key.json"' >> $BASH_ENV
            export GOOGLE_APPLICATION_CREDENTIALS="${HOME}/gcloud-service-key.json"
            gcloud auth configure-docker --quiet

  set_gcloud_config_preprod:
    description: "Authenticate on GCP services and set config and key to be used by other tools that need to authenticate."
    steps:
      - run:
          name: "Set Gcloud Config."
          shell: "/bin/bash -eo pipefail"
          command: |
            echo ${GCLOUD_SERVICE_KEY_PREPROD} | gcloud auth activate-service-account --key-file=-
            gcloud config set project ${GOOGLE_PROJECT_ID}
            gcloud config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud container clusters get-credentials ${GOOGLE_COMPUTE_ZONE} --project=${GOOGLE_PROJECT_ID} --zone=${GOOGLE_COMPUTE_ZONE}
            echo ${GCLOUD_SERVICE_KEY_PREPROD} > ${HOME}/gcloud-service-key.json
            echo 'export GOOGLE_APPLICATION_CREDENTIALS="${HOME}/gcloud-service-key.json"' >> $BASH_ENV
            export GOOGLE_APPLICATION_CREDENTIALS="${HOME}/gcloud-service-key.json"
            gcloud auth configure-docker --quiet

  restore_persisted_env_vars:
    description: "Restore env vars that have been persisted by the previous job."
    steps:
      - run:
          name: Restore persisted env vars
          command: |
            echo "Persisted env vars:"
            cat persisted_env_vars
            cat persisted_env_vars >> $BASH_ENV

  modify_cluster:
    description: "Modify cluster version if needed"
    steps:
      - run:
          name: Modify cluster version
          command: |
            GOOGLE_COMPUTE_ZONE=${GOOGLE_COMPUTE_ZONE_NEXT}
            CLUSTER_NAME=${CLUSTER_NAME_NEXT}
            GOOGLE_CLUSTER_ZONE=${CLUSTER_NAME_NEXT}
            echo export GOOGLE_COMPUTE_ZONE=${GOOGLE_COMPUTE_ZONE} >> $BASH_ENV
            echo export CLUSTER_NAME=${CLUSTER_NAME} >> $BASH_ENV
            echo export GOOGLE_CLUSTER_ZONE=${GOOGLE_CLUSTER_ZONE} >> $BASH_ENV

  install_yq:
    description: "Install yq"
    steps:
      - run:
          name: Install yq
          command: |
            wget https://github.com/mikefarah/yq/releases/download/3.3.1/yq_linux_386
            sudo mv yq_linux_386 /usr/local/bin/yq
            echo "e7fa464149a450d068311a244f403757408a745b  /usr/local/bin/yq" > /tmp/checksum
            sha1sum -c /tmp/checksum
            sudo chmod +x /usr/local/bin/yq

  connector_bigcommerce_checkout_steps:
      description: "Checkout big commerce connector repository"
      steps:
          - run:
                name: BIG COMMERCE CONNECTOR - Ensure to use the ssh key of akeneo-circle-ci account
                command: |
                    ssh-add -D
                    ssh-add ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966
          - when:
              condition:
                  not:
                      equal: [master, << pipeline.git.branch >>]
              steps:
                  - run:
                      name: BIG COMMERCE CONNECTOR - Get connector branch if the same branch exists than the PIM one
                      command: |
                          if git ls-remote --exit-code --heads git@github.com:akeneo/bigcommerce-connector.git ${CIRCLE_BRANCH}; then
                            CONNECTOR_BC_BRANCH=${CIRCLE_BRANCH}
                          else
                            CONNECTOR_BC_BRANCH=master
                          fi
                          echo ${CONNECTOR_BC_BRANCH}
                          echo export CONNECTOR_BC_BRANCH=${CONNECTOR_BC_BRANCH} >> $BASH_ENV
          - when:
              condition:
                  equal: [master, << pipeline.git.branch >>]
              steps:
                  - run:
                      name: BIG COMMERCE CONNECTOR - Get last tagged connector version ready for production
                      command: |
                          CONNECTOR_BC_BRANCH=$(git -c 'versionsort.suffix=-' ls-remote --exit-code --refs --sort='version:refname' --tags git@github.com:akeneo/bigcommerce-connector.git 'v*' | tail -n1 | cut -d'/' -f3)

                          echo export CONNECTOR_BC_BRANCH=${CONNECTOR_BC_BRANCH} >> $BASH_ENV
          - run:
              name: BIG COMMERCE CONNECTOR - Checkout BigCommerce Connector
              command: |
                  mkdir -p tmp
                  echo ${CONNECTOR_BC_BRANCH}
                  git clone --branch $CONNECTOR_BC_BRANCH git@github.com:akeneo/bigcommerce-connector.git tmp/build-connector
                  cd tmp/build-connector
                  echo ${CONNECTOR_BC_BRANCH} > back/VERSION
                  pwd
                  echo `git rev-parse --short HEAD`

  change_pim_onboarder_branch_steps:
      description: "Change Onboarder dependency if same branch exists"
      steps:
          - when:
                condition:
                    not:
                        equal: [master, << pipeline.git.branch >>]
                steps:
                    - run:
                          name: Update composer.json if same branch exists in PIM Onboarder for EE
                          command: |
                              curl -H "Authorization: token ${GITHUB_TOKEN}" \
                                  -H 'Accept: application/vnd.github.v3.raw' \
                                  --output /dev/null --silent --head --fail \
                                  -L https://api.github.com/repos/akeneo/pim-onboarder/contents/README.md?ref=${CIRCLE_BRANCH} && \
                                  ONBOARDER_BRANCH="dev-${CIRCLE_BRANCH}" || ONBOARDER_BRANCH="dev-master"
                                  echo "Update Onboarder dependencie to branch ${ONBOARDER_BRANCH}"
                                  sed -i "s#akeneo/pim-onboarder\": \"^5.0.0#akeneo/pim-onboarder\": \"${ONBOARDER_BRANCH}#" composer.json
