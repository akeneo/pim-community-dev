envVarsDeployDev: &envVarsDeployDev
dockerCloudDeployerNext: &dockerCloudDeployerNext
executor-machine: &executor-machine

jobs:
  # Description :
  #    Create API connection for load tests
  prepare_load_tests:
    parameters:
      # Here to allow dynamic job declaration with workflow deployments_pull_request
      SOURCE_PFID:
        type: string
        default: ""
      PFID:
        type: string
        default: ""
    environment:
      <<: *envVarsDeployDev
    <<: *dockerCloudDeployerNext
    resource_class: small
    steps:
      - attach_workspace:
          at: ~/
      - set_gcloud_config_dev
      - restore_persisted_env_vars
      - run:
          name: Create API connection
          command: |
            PARAM_PFID="<< parameters.PFID >>"
            PFID=${PARAM_PFID:-${PFID}}
            echo "PFID : ${PFID}"
            MYSQL_PASSWORD=$(kubectl get secret -n ${PFID} mysql-secret -o jsonpath='{.data}' | jq -r '."root_password.txt"' | base64 -d)
            kubectl exec -n ${PFID} deployment.apps/mysql -- mysql -u root -p${MYSQL_PASSWORD} akeneo_pim -N -e 'select name from oro_access_group where name in ("admin", "it support", "ecommerce") limit 1;' > oro_access_group.txt
            ORO_ACCESS_GROUP=$(cat oro_access_group.txt)
            echo "USER GROUP : ${ORO_ACCESS_GROUP}"
            
            FQDN=$(kubectl get ingress --no-headers --namespace=${PFID} | head -n 1 | awk '{ print $3 }')
            POD_PIM_WEB=$(kubectl get pods --no-headers --namespace=${PFID} -l component=pim-web | awk 'NR==1{print $1}')
            LOWER_RANGE=100   # inclusive
            UPPER_RANGE=1000   # exclusive
            RANDOM_NUMBER=$(( RANDOM * ( UPPER_RANGE - LOWER_RANGE) / 32767 + LOWER_RANGE ))
            kubectl exec -it -n ${PFID} ${POD_PIM_WEB} -- /bin/bash -c "bin/console akeneo:connectivity-connection:create akeneo_api_k6_dst_${RANDOM_NUMBER} --flow-type data_destination --user-group=\"${ORO_ACCESS_GROUP}\"" > /tmp/api_connection_info
            API_CLIENT_ID=$(cat /tmp/api_connection_info | grep "Client ID: " | awk -F': ' '{printf $2}' | tr -d '\r')
            API_SECRET=$(cat /tmp/api_connection_info | grep "Secret: " | awk -F': ' '{printf $2}' | tr -d '\r')
            API_USERNAME=$(cat /tmp/api_connection_info | grep "Username: " | awk -F': ' '{printf $2}' | tr -d '\r')
            API_PASSWORD=$(cat /tmp/api_connection_info | grep "Password: " | awk -F': ' '{printf $2}' | tr -d '\r')
            
            echo export FQDN=${FQDN} >> $BASH_ENV
            echo export API_CLIENT_ID=${API_CLIENT_ID} >> $BASH_ENV
            echo export API_SECRET=${API_SECRET} >> $BASH_ENV
            echo export API_USERNAME=${API_USERNAME} >> $BASH_ENV
            echo export API_PASSWORD=${API_PASSWORD} >> $BASH_ENV
      - run:
          name: Persist env vars for next jobs
          command: |
            echo export FQDN=${FQDN} >> persisted_env_vars
            echo export API_CLIENT_ID=${API_CLIENT_ID} >> persisted_env_vars
            echo export API_SECRET=${API_SECRET} >> persisted_env_vars
            echo export API_USERNAME=${API_USERNAME} >> persisted_env_vars
            echo export API_PASSWORD=${API_PASSWORD} >> persisted_env_vars
      - persist_to_workspace:
          root: ~/
          paths:
            - project/persisted_env_vars

  # Description :
  #    Use k6 to run perf sanity checks on dev instances
  #    Need prepare_load_tests job before him
  #    This job can be trigged after a deployment, clone, migration or upgrade job
  execute_load_tests:
    parameters:
      # Here to allow dynamic job declaration
      SOURCE_PFID:
        type: string
        default: ""
      TEST:
        type: string
        default: "*"
      DURATION:
        type: string
        default: "10m"
      VUS:
        type: string
        default: "10"
    machine:
      image: *executor-machine
    resource_class: medium
    parallelism: 3
    steps:
      - checkout
      - attach_workspace:
          at: ~/
      - restore_persisted_env_vars
      - run:
          name: Run k6 load tests
          command: |
            mkdir /tmp/k6-artifacts
            TEST=$(circleci tests glob "deployments/test/loadtests/<< parameters.TEST >>.js" | circleci tests split)
            
            echo "Test : $TEST"
            docker run --rm -i grafana/k6 run - <$TEST --env FQDN=${FQDN} --env API_CLIENT_ID=${API_CLIENT_ID} --env API_SECRET=${API_SECRET} --env API_USERNAME=${API_USERNAME} --env API_PASSWORD=${API_PASSWORD} --env K6_DURATION=<< parameters.DURATION >> --env K6_VUS=<< parameters.VUS >> --out json=full.json > /tmp/k6-artifacts/$(basename $TEST).log            
            echo "Test : $TEST"
          when: always
      - run:
          name: K6 logs
          command: |
            cat /tmp/k6-artifacts/*
          when: always
      - store_artifacts:
          path: /tmp/k6-artifacts
