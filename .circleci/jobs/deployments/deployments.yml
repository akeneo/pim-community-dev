envVarsDeployDev: &envVarsDeployDev
envVarsDeployPIMSaaSDev: &envVarsDeployPIMSaaSDev
dockerCloudDeployerCurrent: &dockerCloudDeployerCurrent
dockerCloudDeployerNext: &dockerCloudDeployerNext
dockerPIMDeployerUCS: &dockerPIMDeployerUCS
executor-machine: &executor-machine

jobs:
    # Description :
    #    Deploy k8s environment with the release (IMAGE_TAG) define in previous jobs
    test_deploy:
        parameters:
            PRODUCT_TYPE:
                type: string
                default: "srnt"
            CLUSTER_NEXT:
                type: boolean
                default: false
        environment:
            <<: *envVarsDeployDev
        <<: *dockerCloudDeployerCurrent
        resource_class: small
        steps:
            - attach_workspace:
                  at: ~/
            - add_ssh_keys:
                  fingerprints:
                      - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
            - when:
                  condition:
                      equal: [true, << parameters.CLUSTER_NEXT >> ]
                  steps:
                      - modify_cluster
            - set_gcloud_config_dev
            - restore_persisted_env_vars
            - run:
                  name: Define value for next steps
                  command: |
                      INSTANCE_NAME_PREFIX=pimci
                      INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${IMAGE_TAG_SHORTED}-${CIRCLE_BUILD_NUM}

                      echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                      echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV

                      echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                      echo "Instance name: ${INSTANCE_NAME}"
                      echo "Image tag: ${IMAGE_TAG}"
            - show_datadog_logs_links:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - run:
                  name: Deploy PIM on kubernetes
                  command: |
                      NS=${TYPE}-${INSTANCE_NAME} PHASE=install bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      make -C deployments/ deploy-instance
                      make -C deployments/ commit-instance
            - get_datadog_migration_logs:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - validate_migration:
                instance: ${TYPE}-${INSTANCE_NAME}
            - store_artifacts:
                path: /tmp/migration-logs.json
                destination: migration-logs.json
            - run:
                  name: Test PIM connexion on kubernetes
                  command: make -C deployments/ test-prod
            - run:
                  name: Display Deployment Errors
                  command: cat deployment.log
                  when: on_fail
            - run:
                  name: Prepare infrastructure artifacts
                  command: make -C deployments/ prepare-infrastructure-artifacts
                  when: on_fail
            - store_artifacts:
                  path: ~/artifacts/infra
            - store_artifacts:
                  path: deployment.log
                  destination: test_deploy_<<parameters.PRODUCT_TYPE>>_deployment.log
            - run:
                  name: Remove env on kubernetes
                  command: |
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      UNCOMMIT_INSTANCE_STATUS_CODE=0
                      for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                      exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
                  when: always
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - upgrades.tfplan.json

    # Description :
    #    Deploy k8s environment with the latest release deploy in prod
    test_deploy_last_release:
        parameters:
            PRODUCT_TYPE:
                type: string
                default: "srnt"
            CLUSTER_NEXT:
                type: boolean
                default: false
        environment:
            <<: *envVarsDeployDev
        <<: *dockerCloudDeployerCurrent
        resource_class: small
        steps:
            - attach_workspace:
                  at: ~/
            - add_ssh_keys:
                  fingerprints:
                      - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
            - when:
                  condition:
                      equal: [true, << parameters.CLUSTER_NEXT >> ]
                  steps:
                      - modify_cluster
            - set_gcloud_config_dev
            - restore_persisted_env_vars
            - run:
                  name: Get latest release & export variables
                  command: |
                      TYPE=<<parameters.PRODUCT_TYPE>>
                      echo export TYPE=${TYPE} >> $BASH_ENV

                      LATEST_RELEASE=$(bash ${PWD}/deployments/bin/get_latest_release.sh)

                      if [[ -z "${LATEST_RELEASE}" ]]; then
                          echo "Could not retrieve latest deployed release"
                          exit 1
                      fi

                      INSTANCE_NAME_PREFIX=pimup
                      INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${IMAGE_TAG_SHORTED}-${CIRCLE_BUILD_NUM}

                      echo export LATEST_RELEASE=${LATEST_RELEASE} >> $BASH_ENV
                      echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                      echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV

                      echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                      echo "Instance name: ${INSTANCE_NAME}"
                      echo "Image tag: ${IMAGE_TAG}"
                      echo "Latest image tag: ${LATEST_RELEASE}"
            - show_datadog_logs_links:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - run:
                  name: Pull Terraform modules from last release
                  command: |
                      case ${TYPE} in
                        srnt | grth) BUCKET="serenity-edition-dev" ;;
                        tria) BUCKET="trial-edition-dev"  ;;
                      esac

                      echo "Terraform Bucket Folder: gs://akecld-terraform-modules/${BUCKET}/"

                      rm -r ./deployments
                      BOTO_CONFIG=/dev/null gsutil -m cp -r gs://akecld-terraform-modules/${BUCKET}/${LATEST_RELEASE}/deployments/ .
            - run:
                  name: Deploy instance with latest release
                  command: |
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      IMAGE_TAG=${LATEST_RELEASE} make -C deployments/ deploy-instance
                      IMAGE_TAG=${LATEST_RELEASE} make -C deployments/ commit-instance
            - get_datadog_migration_logs:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - store_artifacts:
                path: /tmp/migration-logs.json
                destination: migration-logs.json
            - run:
                  name: Persist env vars for next jobs
                  command: |
                      echo export TYPE=${TYPE} >> persisted_env_vars
                      echo export INSTANCE_NAME="${INSTANCE_NAME}" >> persisted_env_vars
            - run:
                  name: Remove env on kubernetes
                  command: |
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      UNCOMMIT_INSTANCE_STATUS_CODE=0
                      for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                      exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
                  when: on_fail
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - project/persisted_env_vars

    # Description :
    #    Deploy k8s environment with the release (IMAGE_TAG) define in previous jobs
    #    Keep to k8s environment alive during 1 day
    deploy_pr_environment:
        parameters:
            PRODUCT_TYPE:
                type: string
                default: "srnt"
        environment:
            <<: *envVarsDeployDev
        <<: *dockerCloudDeployerCurrent
        resource_class: small
        steps:
            - attach_workspace:
                  at: ~/
            - add_ssh_keys:
                  fingerprints:
                      - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
            - set_gcloud_config_dev
            - restore_persisted_env_vars
            - run:
                  name: Define value for next steps
                  command: |
                      TYPE="<<parameters.PRODUCT_TYPE>>"
                      INSTANCE_NAME_PREFIX=pimci-pr
                      if [[ "${TYPE}" == "grth" ]]; then
                          INSTANCE_NAME_PREFIX=pimci-pr-ge
                      fi
                      if [[ "${TYPE}" == "tria" ]]; then
                          INSTANCE_NAME_PREFIX=pimci-pr-ft
                      fi
                      INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${CIRCLE_PULL_REQUEST##*/}

                      echo export IMAGE_TAG=${IMAGE_TAG} >> $BASH_ENV
                      echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                      echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV
                      echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
                      echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV

                      echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                      echo "Instance name: ${INSTANCE_NAME}"
                      echo "Image tag: ${IMAGE_TAG}"
            - show_datadog_logs_links:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - run:
                  name: Check Circle CI PR
                  command: |
                      if [[ ${CIRCLE_PULL_REQUEST##*/} == "" ]]; then echo "ERROR : CIRCLE_PULL_REQUEST is empty."; exit 1;fi
                      echo "This environment will be available at https://${INSTANCE_NAME}.dev.cloud.akeneo.com once deployed :)"
            - run:
                  name: Deploy PR environment
                  command: |
                      NS=${TYPE}-${INSTANCE_NAME} PHASE=install bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      make -C deployments/ deploy-instance
                      make -C deployments/ commit-instance
            - get_datadog_migration_logs:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - validate_migration:
                instance: ${TYPE}-${INSTANCE_NAME}
            - store_artifacts:
                path: /tmp/migration-logs.json
                destination: migration-logs.json
            - run:
                  name: Persist env vars for next jobs
                  command: |
                      echo export INSTANCE_NAME="${INSTANCE_NAME}" >> persisted_env_vars
                      echo export INSTANCE_NAME_PREFIX="${INSTANCE_NAME_PREFIX}" >> persisted_env_vars
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - project/persisted_env_vars
            - run:
                  name: Prepare infrastructure artifacts
                  command: make -C deployments/ prepare-infrastructure-artifacts
                  when: on_fail
            - run:
                  name: Remove env on kubernetes
                  command: |
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      UNCOMMIT_INSTANCE_STATUS_CODE=0
                      for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                      exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
                  when: on_fail
            - store_artifacts:
                  path: ~/artifacts/infra

    # Description :
    #    Deploy k8s environment with the release (IMAGE_TAG) define in previous jobs
    #    Adaptation of test_deploy for deployment with edition flags
    #    With EditionFlag we build only a srnt image so we have to migrate editions specific values that were  previously setup and persisted at the builds stage.
    #    These values are set at the beginning of the job at "Define value for cloud-customer files creation" step , with also active EditionFlags with yq
    test_deploy_with_flags:
        parameters:
            PRODUCT_TYPE:
                type: string
                default: "srnt"
            CLUSTER_NEXT:
                type: boolean
                default: false
        environment:
            <<: *envVarsDeployDev
        <<: *dockerCloudDeployerCurrent
        resource_class: small
        steps:
            - attach_workspace:
                  at: ~/
            - add_ssh_keys:
                  fingerprints:
                      - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
            - when:
                  condition:
                      equal: [true, << parameters.CLUSTER_NEXT >> ]
                  steps:
                      - modify_cluster
            - set_gcloud_config_dev
            - install_yq_v3
            - restore_persisted_env_vars
            - run:
                  name: Define values for cloud-customers files creation
                  command: |
                      TYPE=<< parameters.PRODUCT_TYPE >>
                      case ${TYPE} in
                        srnt) TYPE_LONG="serenity" ;;
                        grth) TYPE_LONG="growth_edition" ;;
                        tria) TYPE_LONG="pim_trial" ;;
                      esac

                      PRODUCT_REFERENCE_TYPE="${TYPE_LONG}_instance"
                      PRODUCT_REFERENCE_CODE="${TYPE_LONG}_${ENV_NAME}"

                      echo export TYPE=${TYPE} >> $BASH_ENV
                      echo export TYPE_LONG=${TYPE_LONG} >> $BASH_ENV
                      echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
                      echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV

                      echo "Type: ${TYPE}"
                      echo "Type long: ${TYPE_LONG}"
                      echo "Product reference type: ${PRODUCT_REFERENCE_TYPE}"
                      echo "Product reference code: ${PRODUCT_REFERENCE_CODE}"
            - run:
                  name: Define instance name
                  command: |
                      INSTANCE_NAME_PREFIX=pimci
                      INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${IMAGE_TAG_SHORTED}-${CIRCLE_BUILD_NUM}

                      echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                      echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV

                      echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                      echo "Instance name: ${INSTANCE_NAME}"
                      echo "Image tag: ${IMAGE_TAG}"
            - run:
                  name: Check Edition Flag for next deployment
                  command: |
                        echo "USE_EDITION_FLAG=${USE_EDITION_FLAG}"

                        echo "[DEBUG] Check deployments/terraform/pim/values.yaml -> editionFlag.enabled=$(yq r deployments/terraform/pim/values.yaml editionFlag.enabled)"
                        echo "[DEBUG]editionFlag.enabled must equal false, it will be set to true by terraform at the next step"
                        echo "[DEBUG] Check PIM_EDITION env vars value that will be set in K8S env-configmap.yaml (by HELM < values.yaml ) -> PIM_EDITION: $(yq r deployments/terraform/pim/values.yaml editionFlag.$TYPE)"
            - show_datadog_logs_links:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - run:
                  name: Deploy PIM on kubernetes
                  command: |
                      NS=${TYPE}-${INSTANCE_NAME} PHASE=install bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      make -C deployments/ deploy-instance
                      make -C deployments/ commit-instance
            - get_datadog_migration_logs:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - validate_migration:
                instance: ${TYPE}-${INSTANCE_NAME}
            - store_artifacts:
                path: /tmp/migration-logs.json
                destination: migration-logs.json
            - run:
                  name: Test PIM connexion on kubernetes
                  command: make -C deployments/ test-prod
            - run:
                  name: Display Deployment Errors
                  command: cat deployment.log
                  when: on_fail
            - run:
                  name: Prepare infrastructure artifacts
                  command: make -C deployments/ prepare-infrastructure-artifacts
                  when: on_fail
            - store_artifacts:
                  path: ~/artifacts/infra
            - store_artifacts:
                  path: deployment.log
                  destination: test_deploy_<<parameters.PRODUCT_TYPE>>_deployment.log
            - run:
                  name: Remove env on kubernetes
                  command: |
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      UNCOMMIT_INSTANCE_STATUS_CODE=0
                      for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                      exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
                  when: always
            - run:
                  name: Persist env vars for next jobs
                  command: |
                      echo export TYPE="${TYPE}" >> persisted_env_vars
                      echo export INSTANCE_NAME="${INSTANCE_NAME}" >> persisted_env_vars
                      echo export INSTANCE_NAME_PREFIX="${INSTANCE_NAME_PREFIX}" >> persisted_env_vars
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - upgrades.tfplan.json

    deploy_pr_environment_with_flags:
        parameters:
            PRODUCT_TYPE:
                type: string
                default: "srnt"
        environment:
            <<: *envVarsDeployDev
        <<: *dockerCloudDeployerCurrent
        resource_class: small
        steps:
            - attach_workspace:
                  at: ~/
            - add_ssh_keys:
                  fingerprints:
                      - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
            - set_gcloud_config_dev
            - restore_persisted_env_vars
            - run:
                  name: Define value for cloud-customer files creation for next step
                  command: |
                      TYPE=<< parameters.PRODUCT_TYPE >>

                      case ${TYPE} in
                        srnt) TYPE_LONG="serenity" ;;
                        grth) TYPE_LONG="growth_edition" ;;
                        tria) TYPE_LONG="pim_trial" ;;
                      esac

                      PRODUCT_REFERENCE_TYPE="${TYPE_LONG}_instance"
                      PRODUCT_REFERENCE_CODE="${TYPE_LONG}_${ENV_NAME}"

                      echo export TYPE=${TYPE} >> $BASH_ENV
                      echo export TYPE_LONG=${TYPE_LONG} >> $BASH_ENV
                      echo export PRODUCT_REFERENCE_TYPE=${PRODUCT_REFERENCE_TYPE} >> $BASH_ENV
                      echo export PRODUCT_REFERENCE_CODE=${PRODUCT_REFERENCE_CODE} >> $BASH_ENV

                      echo "Type: ${TYPE}"
                      echo "Type long: ${TYPE_LONG}"
                      echo "Product reference type: ${PRODUCT_REFERENCE_TYPE}"
                      echo "Product reference code: ${PRODUCT_REFERENCE_CODE}"
            - run:
                  name: Define instance name
                  command: |
                      TYPE="<<parameters.PRODUCT_TYPE>>"
                      case ${TYPE} in
                        srnt) INSTANCE_NAME_PREFIX=pimci-pr ;;
                        grth) INSTANCE_NAME_PREFIX="pimci-pr-ge" ;;
                        tria) INSTANCE_NAME_PREFIX=pimci-pr-ft ;;
                      esac

                      INSTANCE_NAME=${INSTANCE_NAME_PREFIX}-${CIRCLE_PULL_REQUEST##*/}

                      echo export IMAGE_TAG=${IMAGE_TAG} >> $BASH_ENV
                      echo export INSTANCE_NAME_PREFIX=${INSTANCE_NAME_PREFIX} >> $BASH_ENV
                      echo export INSTANCE_NAME=${INSTANCE_NAME} >> $BASH_ENV

                      echo "Instance name prefix: ${INSTANCE_NAME_PREFIX}"
                      echo "Instance name: ${INSTANCE_NAME}"
                      echo "Image tag: ${IMAGE_TAG}"
            - run:
                  name: Check Edition Flag for next deployment
                  command: |
                        echo "USE_EDITION_FLAG=$USE_EDITION_FLAG"

                        echo "[DEBUG] Check deployments/terraform/pim/values.yaml -> editionFlag.enabled=$(yq r deployments/terraform/pim/values.yaml editionFlag.enabled)"
                        echo "[DEBUG]editionFlag.enabled must equal false, it will be set to true by terraform at the next step"
                        echo "[DEBUG] Check PIM_EDITION env vars value that will be set in K8S env-configmap.yaml (by HELM < values.yaml ) -> PIM_EDITION: $(yq r deployments/terraform/pim/values.yaml editionFlag.$TYPE)"
            - show_datadog_logs_links:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - run:
                  name: Check Circle CI PR
                  command: |
                      if [[ ${CIRCLE_PULL_REQUEST##*/} == "" ]]; then echo "ERROR : CIRCLE_PULL_REQUEST is empty."; exit 1;fi
                      echo "This environment will be available at https://${INSTANCE_NAME}.dev.cloud.akeneo.com once deployed :)"
            - run:
                  name: Deploy PR environment
                  command: |
                      NS=${TYPE}-${INSTANCE_NAME} PHASE=install bash deployments/bin/deployments_poll_up.sh 2>&1 >> deployment.log &
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      make -C deployments/ deploy-instance
                      make -C deployments/ commit-instance
            - get_datadog_migration_logs:
                pfid: ${TYPE}-${INSTANCE_NAME}
            - validate_migration:
                instance: ${TYPE}-${INSTANCE_NAME}
            - store_artifacts:
                path: /tmp/migration-logs.json
                destination: migration-logs.json
            - run:
                  name: Persist env vars for next jobs
                  command: |
                      echo export TYPE="${TYPE}" >> persisted_env_vars
                      echo export INSTANCE_NAME="${INSTANCE_NAME}" >> persisted_env_vars
                      echo export INSTANCE_NAME_PREFIX="${INSTANCE_NAME_PREFIX}" >> persisted_env_vars
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - project/persisted_env_vars
            - run:
                  name: Prepare infrastructure artifacts
                  command: make -C deployments/ prepare-infrastructure-artifacts
                  when: on_fail
            - run:
                  name: Remove env on kubernetes
                  command: |
                      ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                      export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                      UNCOMMIT_INSTANCE_STATUS_CODE=0
                      for i in 1 2 3; do make -C deployments/ uncommit-instance && UNCOMMIT_INSTANCE_STATUS_CODE=0 && break || UNCOMMIT_INSTANCE_STATUS_CODE=1; done
                      exit ${UNCOMMIT_INSTANCE_STATUS_CODE}
                  when: on_fail
            - store_artifacts:
                  path: ~/artifacts/infra

    test_deploy_ucs_pim:
      parameters:
          CLUSTER_NEXT:
              type: boolean
              default: false
      environment:
          <<: *envVarsDeployPIMSaaSDev
      <<: *dockerPIMDeployerUCS
      resource_class: small
      steps:
        - attach_workspace:
            at: ~/
        - add_ssh_keys:
            fingerprints:
              - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
        - when:
              condition:
                  equal: [true, << parameters.CLUSTER_NEXT >> ]
              steps:
                  - modify_cluster
        - set_gcloud_config_pim_saas_dev
        - set_common_env_vars
        - restore_persisted_env_vars
        - run:
            name: Install yq (v3)
            command: |
              # Same as alias define in commamd>yml without sudo because of alpine/git docker image
              wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64
              mv yq_linux_amd64 /usr/local/bin/yq
              echo "2cc8897984d1ab43b6799aff5eca905d37552fdf  /usr/local/bin/yq" > /tmp/checksum
              sha1sum -c /tmp/checksum
              chmod +x /usr/local/bin/yq
        - run:
            name: Prepare the variables
            command: |
              TENANT_CONTEXT_COLLECTION_NAME="${GOOGLE_CLUSTER_REGION}/${PIM_NAMESPACE}/tenant_contexts"

              TENANT_NAME_PREFIX=ucs # unused for the pim
              TENANT_NAME=${TENANT_NAME_PREFIX}-${IMAGE_TAG_SHORTED}-${CIRCLE_BUILD_NUM} # unused for the pim
              FQDN="${TENANT_NAME}.${GOOGLE_DOMAIN}" # unused for the pim

              TOPIC_BUSINESS_EVENT="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-business-event-${HASH_PR_URL}"
              TOPIC_JOB_QUEUE_UI="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-ui-${HASH_PR_URL}"
              TOPIC_JOB_QUEUE_IMPORT_EXPORT="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-import-export-${HASH_PR_URL}"
              TOPIC_JOB_QUEUE_DATA_MAINTENANCE="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-data-maintenance-${HASH_PR_URL}"
              TOPIC_JOB_QUEUE_SCHEDULED_JOB="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-scheduled-job-${HASH_PR_URL}"

              SUBSCRIPTION_WEBHOOK="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-webhook-${HASH_PR_URL}"
              SUBSCRIPTION_JOB_QUEUE_UI="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-ui-${HASH_PR_URL}"
              SUBSCRIPTION_JOB_QUEUE_IMPORT_EXPORT="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-import-export-${HASH_PR_URL}"
              SUBSCRIPTION_JOB_QUEUE_DATA_MAINTENANCE="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-data-maintenance-${HASH_PR_URL}"
              SUBSCRIPTION_JOB_QUEUE_SCHEDULED_JOB="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${PUBSUB_TOPIC_SHORTED}-job-queue-scheduled-job-${HASH_PR_URL}"

              CLOUD_SCHEDULER_PREFIX="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${CLOUD_SCHEDULER_SHORTED}-job-publisher-${HASH_PR_URL}"
              CLOUD_FUNCTION_NAME="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${CLOUD_FUNCTION_SHORTED}-job-publisher-${HASH_PR_URL}${IMAGE_TAG_DATE}"
              CLOUD_FUNCTION_BUCKET="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${BUCKET_SHORTED}-job-publisher-${HASH_PR_URL}${IMAGE_TAG_DATE}"
              CLOUD_FUNCTION_GSA="pim-cloud-function@${GOOGLE_PROJECT_ID}.iam.gserviceaccount.com"

              TTL_PIM="4260m"

              echo export CIRCLE_BRANCH_LOWER=${CIRCLE_BRANCH_LOWER} >> ${BASH_ENV}
              echo export PIM_NAMESPACE=${PIM_NAMESPACE} >> ${BASH_ENV}
              echo export TENANT_NAME_PREFIX=${TENANT_NAME_PREFIX} >> ${BASH_ENV}
              echo export TENANT_NAME=${TENANT_NAME} >> ${BASH_ENV}
              echo export TENANT_CONTEXT_COLLECTION_NAME=${TENANT_CONTEXT_COLLECTION_NAME}  >> ${BASH_ENV}
              echo export FQDN=${FQDN} >> ${BASH_ENV}
              echo export TOPIC_BUSINESS_EVENT=${TOPIC_BUSINESS_EVENT} >> ${BASH_ENV}
              echo export TOPIC_JOB_QUEUE_UI=${TOPIC_JOB_QUEUE_UI} >> ${BASH_ENV}
              echo export TOPIC_JOB_QUEUE_IMPORT_EXPORT=${TOPIC_JOB_QUEUE_IMPORT_EXPORT} >> ${BASH_ENV}
              echo export TOPIC_JOB_QUEUE_DATA_MAINTENANCE=${TOPIC_JOB_QUEUE_DATA_MAINTENANCE} >> ${BASH_ENV}
              echo export TOPIC_JOB_QUEUE_SCHEDULED_JOB=${TOPIC_JOB_QUEUE_SCHEDULED_JOB} >> ${BASH_ENV}
              echo export SUBSCRIPTION_WEBHOOK=${SUBSCRIPTION_WEBHOOK} >> ${BASH_ENV}
              echo export SUBSCRIPTION_JOB_QUEUE_UI=${SUBSCRIPTION_JOB_QUEUE_UI} >> ${BASH_ENV}
              echo export SUBSCRIPTION_JOB_QUEUE_IMPORT_EXPORT=${SUBSCRIPTION_JOB_QUEUE_IMPORT_EXPORT} >> ${BASH_ENV}
              echo export SUBSCRIPTION_JOB_QUEUE_DATA_MAINTENANCE=${SUBSCRIPTION_JOB_QUEUE_DATA_MAINTENANCE} >> ${BASH_ENV}
              echo export SUBSCRIPTION_JOB_QUEUE_SCHEDULED_JOB=${SUBSCRIPTION_JOB_QUEUE_SCHEDULED_JOB} >> ${BASH_ENV}
              echo export CLOUD_SCHEDULER_PREFIX=${CLOUD_SCHEDULER_PREFIX} >> ${BASH_ENV}
              echo export CLOUD_FUNCTION_NAME=${CLOUD_FUNCTION_NAME} >> ${BASH_ENV}
              echo export CLOUD_FUNCTION_BUCKET=${CLOUD_FUNCTION_BUCKET} >> ${BASH_ENV}
              echo export CLOUD_FUNCTION_GSA=${CLOUD_FUNCTION_GSA} >> ${BASH_ENV}
              echo export TTL_PIM=${TTL_PIM} >> $BASH_ENV
        - run:
              name: DATADOG deployment Livetail logs page
              command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${PIM_NAMESPACE}"
        - run:
            name: Create K8S artifact deployement branch
            command: |
              ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
              export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
              git config --global user.email "pim_ci@akeneo.com"
              git config --global user.name "pim_ci_deployment"

              cd /tmp
              git clone -b ${CIRCLE_BRANCH} --depth 1 git@github.com:akeneo/pim-enterprise-dev.git
              git clone -b ${CIRCLE_BRANCH} git@github.com:akeneo/pim-saas-k8s-artifacts.git && cd pim-saas-k8s-artifacts || { git clone git@github.com:akeneo/pim-saas-k8s-artifacts.git && cd pim-saas-k8s-artifacts && git checkout -b ${CIRCLE_BRANCH}; }
              rm -rf /tmp/pim-saas-k8s-artifacts/pim-saas-service
              mv /tmp/pim-enterprise-dev/deployments-ucs/pim-saas-service /tmp/pim-saas-k8s-artifacts/pim-saas-service

              ## Create the values.yaml (values.yaml overide by values-ci.yaml)
              cp /tmp/pim-enterprise-dev/deployments-ucs/config/values-pim-ci.yaml /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml

              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml global.extraLabels.tenant_name "${TENANT_NAME}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml common.gcpFireStoreProjectID "${GOOGLE_PROJECT_ID_FIRESTORE}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml common.gcpProjectID "${GOOGLE_PROJECT_ID}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml common.location "${GOOGLE_LOCATION}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml common.fqdn "${FQDN}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml common.dnsCloudDomain "${GOOGLE_DOMAIN}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml common.region "${GOOGLE_CLUSTER_REGION}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml common.tenantContext "${TENANT_CONTEXT_COLLECTION_NAME}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml image.pim.tag "${IMAGE_TAG}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.topicBusinessEvent "${TOPIC_BUSINESS_EVENT}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.topicJobQueueUI "${TOPIC_JOB_QUEUE_UI}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.topicJobQueueImportExport "${TOPIC_JOB_QUEUE_IMPORT_EXPORT}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.topicJobQueueDataMaintenance "${TOPIC_JOB_QUEUE_DATA_MAINTENANCE}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.topicJobQueueScheduledJob "${TOPIC_JOB_QUEUE_SCHEDULED_JOB}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.subscriptionWebhook "${SUBSCRIPTION_WEBHOOK}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.subscriptionJobQueueUI "${SUBSCRIPTION_JOB_QUEUE_UI}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.subscriptionJobQueueImportExport "${SUBSCRIPTION_JOB_QUEUE_IMPORT_EXPORT}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.subscriptionJobQueueDataMaintenance "${SUBSCRIPTION_JOB_QUEUE_DATA_MAINTENANCE}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.pubsub.subscriptionJobQueueScheduledJob "${SUBSCRIPTION_JOB_QUEUE_SCHEDULED_JOB}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.cloudFunction.name "${CLOUD_FUNCTION_NAME}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.cloudFunction.bucket "${CLOUD_FUNCTION_BUCKET}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.cloudFunction.serviceAccountEmail "${CLOUD_FUNCTION_GSA}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/values-ci.yaml pim.jobsPrefix "${CLOUD_SCHEDULER_PREFIX}"

              ## Charts
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/Chart.yaml appVersion ${IMAGE_TAG}

              ## ArgoCD
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml spec.source.targetRevision ${CIRCLE_BRANCH}
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml spec.destination.namespace ${PIM_NAMESPACE}
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml metadata.name ${PIM_NAMESPACE}
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml metadata.labels.name ${PIM_NAMESPACE}
              # https://codeberg.org/hjacobs/kube-janitor#ttl
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml metadata.annotations."janitor/ttl" "${TTL_PIM}"
              yq w -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml spec.source.helm.valueFiles[+] values-ci.yaml
              # Remove automated SYNC
              yq d -i /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml spec.syncPolicy.automated

              git add pim-saas-service
              git commit -m "Update release version" || true
              git push --set-upstream origin ${CIRCLE_BRANCH}
        - run:
            name: Deploy PIM
            command: |
              kubectl apply -f /tmp/pim-saas-k8s-artifacts/pim-saas-service/argocd-app/pim-application.yaml -n argocd

              # Better to store the password in CircleCI or other mecanisme
              ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)

              # Login to argocd call k8s
              kubectl config set-context --current --namespace=argocd
              argocd login --core argocd-${GOOGLE_CLUSTER_REGION}.${GOOGLE_DOMAIN} --username admin --password ${ARGOCD_PASSWORD}

              # Stop operation in progress is exist
              argocd app terminate-op ${PIM_NAMESPACE} --core && argocd app wait --operation ${PIM_NAMESPACE} --core || true
              argocd app get ${PIM_NAMESPACE} --hard-refresh --core
              argocd app sync ${PIM_NAMESPACE} --prune --core
              argocd app wait --sync --health --operation ${PIM_NAMESPACE} --core
              echo "argocd app sync successfull"

              echo "============================"
              echo "Argocd access:"
              echo "url : https://argocd-${GOOGLE_CLUSTER_REGION}.${GOOGLE_DOMAIN}"
              echo "user : admin"
              echo "password : ${ARGOCD_PASSWORD}"
              echo "============================"
        - run:
              name: Remove env on kubernetes on failure
              command: |
                  ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)

                  # Login to argocd call k8s
                  kubectl config set-context --current --namespace=argocd
                  argocd login --core argocd-${GOOGLE_CLUSTER_REGION}.${GOOGLE_DOMAIN} --username admin --password ${ARGOCD_PASSWORD}

                  echo "      argocd app terminate-op ${PIM_NAMESPACE} --core || true"
                  echo "      kubectl delete app ${PIM_NAMESPACE} -n argocd || true"
                  echo "      kubectl delete ${PIM_NAMESPACE}"
                  argocd app terminate-op ${PIM_NAMESPACE} --core || true
                  kubectl delete app ${PIM_NAMESPACE} -n argocd || true
                  kubectl delete ns ${PIM_NAMESPACE}
              when: on_fail

    test_deploy_ucs_tenant:
        parameters:
            CLUSTER_NEXT:
                type: boolean
                default: false
            PIM_EDITION:
                type: string
                default: "serenity_instance"
            DEPLOY_PR:
                type: boolean
                default: false
            tenant_name:
                type: string
                default: ''
        environment:
            <<: *envVarsDeployPIMSaaSDev
        <<: *dockerPIMDeployerUCS
        resource_class: small
        steps:
            - attach_workspace:
                  at: ~/
            - add_ssh_keys:
                fingerprints:
                  - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
            - when:
                  condition:
                      equal: [true, << parameters.CLUSTER_NEXT >> ]
                  steps:
                      - modify_cluster
            - set_gcloud_config_pim_saas_dev
            - set_common_env_vars
            - restore_persisted_env_vars
            - restore_persisted_timmy_env_vars
            - run:
                name: Install yq (v3)
                command: |
                  # Same as alias define in commamd>yml without sudo because of alpine/git docker image
                  wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64
                  mv yq_linux_amd64 /usr/local/bin/yq
                  echo "2cc8897984d1ab43b6799aff5eca905d37552fdf  /usr/local/bin/yq" > /tmp/checksum
                  sha1sum -c /tmp/checksum
                  chmod +x /usr/local/bin/yq
            - run:
                  name: Define value for next steps
                  command: |
                      DEPLOY_PR=$(echo << parameters.DEPLOY_PR >>)
                      if [ ${DEPLOY_PR} = "false" ]; then
                        TENANT_NAME_PREFIX="ucs-ci-ee"
                        TENANT_NAME="${TENANT_NAME_PREFIX}-${IMAGE_TAG_SHORTED}-${CIRCLE_BUILD_NUM}"
                      else
                        TENANT_NAME_PREFIX="ucs-pr-ee"
                        TENANT_NAME=$(echo "${TENANT_NAME_PREFIX}-${CIRCLE_BRANCH_LOWER}" | cut -c -50)
                      fi
                      if [ ! << parameters.tenant_name >> = "" ]; then
                        TENANT_NAME=<< parameters.tenant_name >>
                      fi
                      TENANT_ID=${TYPE}-${TENANT_NAME}
                      FQDN="${TENANT_NAME}.${GOOGLE_DOMAIN}"
                      TTL_TENANT="4320m"

                      echo export TENANT_NAME_PREFIX=${TENANT_NAME_PREFIX} >> ${BASH_ENV}
                      echo export TENANT_NAME=${TENANT_NAME} >> ${BASH_ENV}
                      echo export TENANT_ID=${TENANT_ID} >> ${BASH_ENV}
                      echo export TTL_TENANT=${TTL_TENANT} >> $BASH_ENV
                      echo export FQDN=${FQDN} >> ${BASH_ENV}

                      echo "Tenant name: ${TENANT_NAME}"
                      echo "Tenant URL: ${FQDN}"
                      echo "Image tag: ${IMAGE_TAG}"
            - run:
                  name: DATADOG deployment Livetail logs page
                  command: echo "https://app.datadoghq.eu/logs/livetail?query=kube_namespace%3A${TENANT_ID}"
            - run:
                name: Get back the deployment branch
                command: |
                  ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                  export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                  git config --global user.email "pim_ci@akeneo.com"
                  git config --global user.name "pim_ci_deployment"

                  cd /tmp
                  git clone -b ${CIRCLE_BRANCH} --depth 1 git@github.com:akeneo/pim-enterprise-dev.git
                  git clone -b ${CIRCLE_BRANCH} git@github.com:akeneo/pim-saas-k8s-artifacts.git && cd pim-saas-k8s-artifacts || { git clone git@github.com:akeneo/pim-saas-k8s-artifacts.git && cd pim-saas-k8s-artifacts && git checkout -b ${CIRCLE_BRANCH}; }
                  rm -rf /tmp/pim-saas-k8s-artifacts/tenant
                  mv /tmp/pim-enterprise-dev/deployments-ucs/tenant /tmp/pim-saas-k8s-artifacts/tenant

                  ## Update the values.yaml with the correct image tag
                  yq w -i /tmp/pim-enterprise-dev/deployments-ucs/config/values-tenant-ci.yaml image.pim.tag "${IMAGE_TAG}"
                  yq m -i -x /tmp/pim-saas-k8s-artifacts/tenant/values.yaml /tmp/pim-enterprise-dev/deployments-ucs/config/values-tenant-ci.yaml

                  ## Charts
                  yq w -i /tmp/pim-saas-k8s-artifacts/tenant/Chart.yaml appVersion ${IMAGE_TAG}

                  ## ArgoCD
                  yq w -i /tmp/pim-saas-k8s-artifacts/tenant/argocd-app/tenant-application.yaml spec.source.targetRevision ${CIRCLE_BRANCH}

                  git add tenant || true
                  git commit -m "Update tenant version" || true
                  git push --set-upstream origin ${CIRCLE_BRANCH} || true
            - run:
                  name: Sync the tenant if the tenant already exist
                  command: |
                      # Will failed if there is no application found
                      APP_NAME=$(kubectl get application -n argocd | grep ${TENANT_ID} | awk '{print $1}') || true
                      if [ "${APP_NAME}" != "${TENANT_ID}" ]; then
                        echo "The tenant ${TENANT_ID} doesn't exit, we need to create it"
                        exit 0
                      fi

                      TENANT_EXIST=true
                      echo export TENANT_EXIST=${TENANT_EXIST} >> ${BASH_ENV}

                      # Better to store the password in CircleCI or other mecanisme
                      ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)

                      # Login to argocd call k8s
                      kubectl config set-context --current --namespace=argocd
                      argocd login --core argocd-${GOOGLE_CLUSTER_REGION}.${GOOGLE_DOMAIN} --username admin --password ${ARGOCD_PASSWORD}
                      argocd app get ${TENANT_ID} --hard-refresh --core
                      argocd app wait --sync --health --operation ${TENANT_ID} --core

                      # Check if hook failed
                      STATUS_HEALTH=$(argocd app get ${TENANT_ID} | grep Failed | awk '{print $6}') || true
                      if [ -n "${STATUS_HEALTH}" ]; then
                        echo "Error when deploying argocd app"
                        exit 1
                      fi
                      echo "argocd app sync successfull"

                      echo "============================"
                      echo "Argocd access:"
                      echo "url : https://argocd-${GOOGLE_CLUSTER_REGION}.${GOOGLE_DOMAIN}"
                      echo "user : admin"
                      echo "password : ${ARGOCD_PASSWORD}"
                      echo "============================"
            - run:
                  name: Deploy Tenant with Timmy
                  command: |
                      if [ "${TENANT_EXIST}" == "true" ]; then
                        echo "The tenant ${TENANT_ID} exits and is already SYNC, we don't need to recreate it"
                        exit 0
                      fi
                      JSON_BODY_STRING=\''{"annotations":{"kube-janitor":"'"${TTL_TENANT}"'"},"pim_edition":"'"<<parameters.PIM_EDITION>>"'","branchName":"'"${CIRCLE_BRANCH}"'","tenant_name":"'"${TENANT_NAME}"'","dnsCloudDomain":"'"${GOOGLE_DOMAIN}"'","pim":{"defaultAdminUser":{"login":"'"${CIRCLE_BRANCH_LOWER}"'@akeneo.com","firstName":"'"${CIRCLE_BRANCH_LOWER}"'","lastName":"'"${CIRCLE_BRANCH_LOWER}"'","email":"'"${CIRCLE_BRANCH_LOWER}"'@akeneo.com","uiLocale":"en_US"},"api":{"namespace":"'"${PIM_NAMESPACE}"'"},"web":{"namespace":"'"${PIM_NAMESPACE}"'"}}}'
                      JSON_BODY_STRING=${JSON_BODY_STRING:1}

                      CLOUD_FUNCTION_URL=$(gcloud beta functions describe ${CLOUD_FUNCTION_CREATE_TENANT} --format='value(serviceConfig.uri)' --gen2 --region=${GOOGLE_CLUSTER_REGION})

                      echo "Cloud function URL: ${CLOUD_FUNCTION_URL}"
                      echo "Cloud function body: ${JSON_BODY_STRING}"

                      curl --fail-with-body -m 3610 -X POST ${CLOUD_FUNCTION_URL} -H "Authorization: bearer $(gcloud auth print-identity-token)" -H "Content-Type: application/json" -d ${JSON_BODY_STRING}

                      # Better to store the password in CircleCI or other mecanisme
                      ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)

                      # Login to argocd call k8s
                      kubectl config set-context --current --namespace=argocd
                      argocd login --core argocd-${GOOGLE_CLUSTER_REGION}.${GOOGLE_DOMAIN} --username admin --password ${ARGOCD_PASSWORD}
                      argocd app wait --sync --health --operation ${TENANT_ID} --core

                      # Check if hook failed
                      STATUS_HEALTH=$(argocd app get ${TENANT_ID} | grep Failed | awk '{print $6}') || true
                      if [ -n "${STATUS_HEALTH}" ]; then
                        echo "Error when deploying argocd app"
                        exit 1
                      fi
                      echo "argocd app sync successfull"

                      echo "============================"
                      echo "Argocd access:"
                      echo "url : https://argocd-${GOOGLE_CLUSTER_REGION}.${GOOGLE_DOMAIN}"
                      echo "user : admin"
                      echo "password : ${ARGOCD_PASSWORD}"
                      echo "============================"
            - run:
                  name: Display login information
                  command: |
                      # Get back the creadential to login to the pim
                      TENANT_FQDN=$(kubectl describe application ${TENANT_ID} -n argocd | grep common.fqdn -A 1 | awk 'NR==2' | awk '{print $2}')
                      TENANT_LOGIN=$(kubectl describe application ${TENANT_ID} -n argocd | grep pim.defaultAdminUser.login -A 1 | awk 'NR==2' | awk '{print $2}')
                      TENANT_PASSWORD=$(kubectl describe application ${TENANT_ID} -n argocd | grep pim.defaultAdminUser.password -A 1 | awk 'NR==2' | awk '{print $2}')

                      echo "============================"
                      echo "url : https://${TENANT_FQDN}"
                      echo "user : ${TENANT_LOGIN}"
                      echo "password : ${TENANT_PASSWORD}"
                      echo "============================"
            - run:
                  name: Persist env vars for next jobs
                  command: |
                      echo export TENANT_NAME="${TENANT_NAME}" >> persisted_env_vars
                      echo export TENANT_ID="${TENANT_ID}" >> persisted_env_vars
                      echo export FQDN="${FQDN}" >> persisted_env_vars
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - project/persisted_env_vars
            - run:
                  name: Remove env on kubernetes
                  command: |
                      JSON_BODY_STRING=$(printf "{\"branchName\":\"%s\",\"tenant_name\":\"%s\"}\n" ${CIRCLE_BRANCH} ${TENANT_NAME} )

                      gcloud config unset auth/impersonate_service_account

                      DELETE_TENANT_STATUS_CODE=0
                      gcloud beta functions call ${CLOUD_FUNCTION_DELETE_TENANT} --region=${GOOGLE_CLUSTER_REGION}  --data  ${JSON_BODY_STRING} --gen2 || DELETE_TENANT_STATUS_CODE=1

                      echo "      Timmy delete ${TENANT_ID}"
                      kubectl delete ns ${TENANT_ID}
                      exit ${DELETE_TENANT_STATUS_CODE}
                  when: on_fail

    test_deploy_timmy:
        parameters:
            CLUSTER_NEXT:
                type: boolean
                default: false
        environment:
            <<: *envVarsDeployPIMSaaSDev
        <<: *dockerPIMDeployerUCS
        resource_class: small
        steps:
            - attach_workspace:
                  at: ~/
            - when:
                  condition:
                      equal: [true, << parameters.CLUSTER_NEXT >> ]
                  steps:
                      - modify_cluster
            - set_gcloud_config_pim_saas_dev
            - set_common_env_vars
            - restore_persisted_env_vars
            - add_ssh_keys:
                  fingerprints:
                      - "1f:25:f8:bb:59:52:95:f6:e2:f2:97:2f:30:d4:e9:66"
            - run:
                    name: Check changes for Timmy
                    command: |
                        ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
                        export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_1f25f8bb595295f6e2f2972f30d4e966 -o UserKnownHostsFile=~/.ssh/known_hosts -o IdentitiesOnly=Yes'
                        git config --global user.email "pim_ci@akeneo.com"
                        git config --global user.name "pim_ci_deployment"

                        git clone --depth 1 git@github.com:akeneo/pim-enterprise-dev.git /tmp/pim-enterprise-dev
                        # Will failed if there is no diff found
                        FILES_LIST=$(diff -qr /tmp/pim-enterprise-dev/deployments-ucs/timmy deployments-ucs/timmy) || true
                        echo "List of changes : ${FILES_LIST}"

                        if [ -n "${FILES_LIST}" ]; then
                          SKIP_DEPLOY_TIMMY=false
                          CLOUD_FUNCTION_CREATE_TENANT="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${CLOUD_FUNCTION_SHORTED}-timmy-create-tenant-${HASH_PR_URL}"
                          CLOUD_FUNCTION_DELETE_TENANT="${ENV_NAME_SHORTED}-${GOOGLE_REGION_SHORTED}-${CLOUD_FUNCTION_SHORTED}-timmy-delete-tenant-${HASH_PR_URL}"
                        fi
                        TERRAFORM_PATH="deployments-ucs/timmy/terraform/${ENV_NAME}"

                        echo export SKIP_DEPLOY_TIMMY=${SKIP_DEPLOY_TIMMY} >> ${BASH_ENV}
                        echo export CLOUD_FUNCTION_CREATE_TENANT=${CLOUD_FUNCTION_CREATE_TENANT} >> ${BASH_ENV}
                        echo export CLOUD_FUNCTION_DELETE_TENANT=${CLOUD_FUNCTION_DELETE_TENANT} >> ${BASH_ENV}
                        echo export TERRAFORM_PATH=${TERRAFORM_PATH} >> ${BASH_ENV}

                        echo "Path terraform: ${TERRAFORM_PATH}"
            - run:
                    name: Stop the job if there is no changes
                    command: |
                        if [ "${SKIP_DEPLOY_TIMMY}" == true ]; then
                          circleci step halt
                        fi
            - run:
                  name: Init and Plan terraform
                  command: |
                    cd ${TERRAFORM_PATH}
                    terraform init -backend-config="prefix=timmy/${GOOGLE_PROJECT_ID}/${GOOGLE_CLUSTER_REGION}" -reconfigure
                    terraform workspace select ${CIRCLE_BRANCH_LOWER} || terraform workspace new ${CIRCLE_BRANCH_LOWER}
                    terraform plan -var-file=./vars/${GOOGLE_CLUSTER_REGION}.tfvars -var branch_name=${CIRCLE_BRANCH_LOWER} -var suffix_name=${HASH_PR_URL} -var enable_request_portal_cloud_function=false -var enable_request_portal_cloud_scheduler=false
            - run:
                  name: Init and Apply terraform
                  command: |
                      cd ${TERRAFORM_PATH}
                      terraform init -backend-config="prefix=timmy/${GOOGLE_PROJECT_ID}/${GOOGLE_CLUSTER_REGION}" -reconfigure
                      terraform workspace select ${CIRCLE_BRANCH_LOWER} || terraform workspace new ${CIRCLE_BRANCH_LOWER}
                      terraform apply -auto-approve -input=false -var-file=./vars/${GOOGLE_CLUSTER_REGION}.tfvars -var branch_name=${CIRCLE_BRANCH_LOWER} -var suffix_name=${HASH_PR_URL} -var enable_request_portal_cloud_function=false -var enable_request_portal_cloud_scheduler=false
            - run:
                  name: Persist env vars for next jobs
                  command: |
                      echo export SKIP_DEPLOY_TIMMY=${SKIP_DEPLOY_TIMMY} >> persisted_timmy_env_vars
                      echo export CLOUD_FUNCTION_CREATE_TENANT=${CLOUD_FUNCTION_CREATE_TENANT} >> persisted_timmy_env_vars
                      echo export CLOUD_FUNCTION_DELETE_TENANT=${CLOUD_FUNCTION_DELETE_TENANT} >> persisted_timmy_env_vars
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - project/persisted_timmy_env_vars
